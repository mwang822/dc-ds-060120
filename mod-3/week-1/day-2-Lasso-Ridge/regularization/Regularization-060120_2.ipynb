{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "__Content__\n",
    "\n",
    "- [Objectives](#objectives)\n",
    "\n",
    "- [Review](#review)\n",
    "\n",
    "- [Regularization Techniques](#regularization_techniques)\n",
    "\n",
    "- [Questions](#questions)\n",
    "\n",
    "- [Appendix](#appendix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Objectives \n",
    "<a name=\"objectives\"></a>\n",
    "\n",
    "- Understand what is regularization\n",
    "\n",
    "- Understand the effect of hyper-parameter $\\alpha$ in Ridge and Lasso.\n",
    "\n",
    "- Understand the similarities and differences between Lasso-Ridge-Linear models.\n",
    "\n",
    "- Apply Lasso and Ridge with sklearn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Review\n",
    "<a name=\"review\"></a>\n",
    "\n",
    "\n",
    "\n",
    "[__Overfitting - Underfitting__](https://github.com/gokererdogan/JaverianaMLCourse/blob/master/Lectures/05.pdf)\n",
    "\n",
    "<img src=\"underfitting_overfitting.png\" alt=\"Bias-Variance\" style=\"width: 500px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "\n",
    "\n",
    "[__Bias - Variance Trade-Off__](http://scott.fortmann-roe.com/docs/BiasVariance.html)\n",
    "\n",
    "<img src=\"bias_variance_trade_off.png\" alt=\"Bias-Variance\" style=\"width: 400px;\"/>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Preliminaries - L1 and L2 Norms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Suppose we have a vector:  \n",
    "\n",
    "$$\n",
    "  \\begin{align}\n",
    "    X &= \\begin{bmatrix}\n",
    "           x_{1} \\\\\n",
    "           x_{2} \\\\\n",
    "           x_{3} \\\\\n",
    "           x_{4}\n",
    "         \\end{bmatrix}\n",
    "  \\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Then the square of the \"__L2-norm__\" of this vector is given by:\n",
    "\n",
    "$$ \\| X \\|^{2}_{2} = x_{1}^{2} + x_{2}^{2} + x_{3}^{2} +x_{4}^{2} = \\sum_{i=1}^{4} x_{i}^{2}$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31.12876483254676"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## using numpy:\n",
    "import numpy as np\n",
    "X = np.array([12, -25, 10, -10])\n",
    "\n",
    "##L2 norm of X\n",
    "np.sqrt(sum(X*X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Similarly the \"__L1-norm__\" of the X is given as:\n",
    "\n",
    "$$ \\| X \\|_{1} = \\lvert x_{1}\\rvert + \\lvert x_{2}\\rvert + \\lvert x_{3}\\rvert + \\lvert x_{4}\\rvert = \\sum_{i=1}^{4} \\lvert x_{i}\\rvert $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.449489742783178 4\n"
     ]
    }
   ],
   "source": [
    "X = np.array([2, 0, 1, -1])\n",
    "l1_norm = sum(np.abs(X))\n",
    "l1_norm\n",
    "l2_norm = np.sqrt(sum(X*X))\n",
    "\n",
    "print(l2_norm, l1_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "In two dimensions: If $$\n",
    "  \\begin{align}\n",
    "    X &= \\begin{bmatrix}\n",
    "           x_{1} \\\\\n",
    "           x_{2} \\\\\n",
    "         \\end{bmatrix}\n",
    "  \\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "$$\\text{(Lasso) ---->} \\| X \\|_{1} = \\lvert x_{1}\\rvert + \\lvert x_{2}\\rvert = \\sum_{i=1}^{2} \\lvert x_{i}\\rvert $$\n",
    "\n",
    "$$\\text{(Ridge) ---->} \\| X \\|_{2}^{2} = \\lvert x_{1}\\rvert^{2} + \\lvert x_{2}\\rvert^{2} = \\sum_{i=1}^{2} \\lvert x_{i}\\rvert^{2} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"norms.png\" alt=\"Lasso-Lambda\" style=\"width: 400px;\" class = \"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Examples: Note that if we have two vectors $ \\begin{align}\n",
    "    X &= \\begin{bmatrix}\n",
    "           x_{1} \\\\\n",
    "           x_{2} \\\\\n",
    "           x_{3} \\\\\n",
    "           x_{4}\n",
    "         \\end{bmatrix}\n",
    "  \\end{align}$   and $ \\begin{align}\n",
    "    Y &= \\begin{bmatrix}\n",
    "           y_{1} \\\\\n",
    "           y_{2} \\\\\n",
    "           y_{3} \\\\\n",
    "           y_{4}\n",
    "         \\end{bmatrix}\n",
    "  \\end{align}$ we can subtract them and get a new vector: $ \\begin{align}\n",
    "    X - Y &= \\begin{bmatrix}\n",
    "           x_{1} - y_{1} \\\\\n",
    "           x_{2} - y_{2}\\\\\n",
    "           x_{3} - y_{3}\\\\\n",
    "           x_{4} - y_{4}\n",
    "         \\end{bmatrix}\n",
    "  \\end{align}$. Then now we can calculate the __L1-norm__ of the new vector $X-Y$ as:\n",
    "  \n",
    "  $$ \\| X-Y \\|_{1} = \\lvert x_{1} - y_{1} \\rvert + \\lvert x_{2} - y_{2} \\rvert + \\lvert x_{3} - y_{3} \\rvert + \\lvert x_{4} - y_{4} \\rvert = \\sum\\limits_{i=1}^{4} \\lvert x_{i} - y_{i} \\rvert$$\n",
    "  \n",
    "  Similarly the __L2-norm__ of this vector is given by:\n",
    "  \n",
    "  $$ \\| X-Y \\|_{2}^{2} =  (x_{1} - y_{1})^{2} + (x_{2} - y_{2} )^{2} + ( x_{3} - y_{3} )^{2} + ( x_{4} - y_{4} )^{2} =\\sum\\limits_{i=1}^{4} ( x_{i} - y_{i} )^{2} $$\n",
    "  \n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Linear Regression Recap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "#### Linear Model\n",
    "\n",
    "$$ Y = w_{0} + w_{1}X_1 + w_{2}X_{2} + \\cdots + w_{p}X_{p} + \\varepsilon $$\n",
    "\n",
    " - We train model to understand the paramaters $w_{i}$ (Coefficients) \n",
    "\n",
    " - $X_{i}$ 's are columns of the datasets (Features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Once the coefficients are estimated (learned): We can make predictions for an observation (row) in our dataset:\n",
    "\n",
    " $$ \\hat{y}_{i} =  \\hat{w}_{0} + \\hat{w}_{1}X_{i1} + \\hat{w}_{2}X_{i2} + \\cdots + \\hat{w}_{p}X_{ip}$$\n",
    " \n",
    " - $\\hat{w}_{i}$'s are estimated coefficients\n",
    " - $X_{i1}, X_{i2}, \\cdots, X_{ip}$ - i'th row in the dataset (with p-columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    " \n",
    " Therefore for each observations (rows) errors are given by:\n",
    " \n",
    " $$ e_{i} = y_{i} - \\hat{y}_{i} $$\n",
    " \n",
    " As a result, the Residual Sum of Squares can be expressed as:\n",
    " \n",
    " $$ RSS(\\hat{w}_{0}, \\cdots, \\hat{w}_{p}) = \\sum\\limits_{i=0}^{N} e_{i}^{2}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "\n",
    "Usually the cost functions are denoted with the capital letter $J$\n",
    " \n",
    " \n",
    " $$ J(\\hat{w}_{0}, \\cdots, \\hat{w}_{p}) = \\sum\\limits_{i=0}^{N} (y_{i} - \\hat{w}_{0} - \\hat{w}_{1}X_{i1} - \\hat{w}_{2}X_{i2} - \\cdots - \\hat{w}_{p}X_{i_p})^{2} $$\n",
    " \n",
    " And this equation can be written in short hand as:\n",
    " \n",
    " $$ J(\\boldsymbol{w}) = \\| \\boldsymbol{Y} - X \\hat{w} \\|_{2}^{2} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Ridge regularization\n",
    "\n",
    "Instead of minimizing $J(w)$ (least squares method), we will minimize:\n",
    "\n",
    "$$ J_{\\alpha}(\\boldsymbol{w}) = J(\\boldsymbol{w}) + \\alpha\\sum_{i=1}^{p} w_{i}^{2} $$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### Lasso regularization\n",
    "\n",
    "Instead of minimizing $J(\\boldsymbol{w})$, we will minimize:\n",
    "\n",
    "$$ J_{\\alpha}(\\boldsymbol{w}) = J(\\boldsymbol{w}) + \\alpha\\sum_{i=1}^{p}| w_{i} | $$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Regularization Techniques\n",
    "\n",
    "<a name=\"regularization_techniques\"></a>\n",
    "\n",
    "\n",
    "- Why?\n",
    "\n",
    "    - Reduces complexity\n",
    "    \n",
    "    - Reduce the chance of overfitting.\n",
    "    \n",
    "    - Reduces model's variance at the expense of introducing small bias\n",
    "    \n",
    "    - Increases model's interprettability.\n",
    "    \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## An Example with Sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## import libraries\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from pandas.plotting import scatter_matrix\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data \n",
    "import pandas as pd\n",
    "df = pd.read_csv('../data/Credit.csv', index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400, 11)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Income</th>\n",
       "      <th>Limit</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Cards</th>\n",
       "      <th>Age</th>\n",
       "      <th>Education</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Student</th>\n",
       "      <th>Married</th>\n",
       "      <th>Ethnicity</th>\n",
       "      <th>Balance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14.891</td>\n",
       "      <td>3606</td>\n",
       "      <td>283</td>\n",
       "      <td>2</td>\n",
       "      <td>34</td>\n",
       "      <td>11</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>106.025</td>\n",
       "      <td>6645</td>\n",
       "      <td>483</td>\n",
       "      <td>3</td>\n",
       "      <td>82</td>\n",
       "      <td>15</td>\n",
       "      <td>Female</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Asian</td>\n",
       "      <td>903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>104.593</td>\n",
       "      <td>7075</td>\n",
       "      <td>514</td>\n",
       "      <td>4</td>\n",
       "      <td>71</td>\n",
       "      <td>11</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Asian</td>\n",
       "      <td>580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>148.924</td>\n",
       "      <td>9504</td>\n",
       "      <td>681</td>\n",
       "      <td>3</td>\n",
       "      <td>36</td>\n",
       "      <td>11</td>\n",
       "      <td>Female</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Asian</td>\n",
       "      <td>964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>55.882</td>\n",
       "      <td>4897</td>\n",
       "      <td>357</td>\n",
       "      <td>2</td>\n",
       "      <td>68</td>\n",
       "      <td>16</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>331</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Income  Limit  Rating  Cards  Age  Education  Gender Student Married  \\\n",
       "1   14.891   3606     283      2   34         11    Male      No     Yes   \n",
       "2  106.025   6645     483      3   82         15  Female     Yes     Yes   \n",
       "3  104.593   7075     514      4   71         11    Male      No      No   \n",
       "4  148.924   9504     681      3   36         11  Female      No      No   \n",
       "5   55.882   4897     357      2   68         16    Male      No     Yes   \n",
       "\n",
       "   Ethnicity  Balance  \n",
       "1  Caucasian      333  \n",
       "2      Asian      903  \n",
       "3      Asian      580  \n",
       "4      Asian      964  \n",
       "5  Caucasian      331  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's see the head of the dataset\n",
    "print(df.shape)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A Brief Investigation of the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 400 entries, 1 to 400\n",
      "Data columns (total 11 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   Income     400 non-null    float64\n",
      " 1   Limit      400 non-null    int64  \n",
      " 2   Rating     400 non-null    int64  \n",
      " 3   Cards      400 non-null    int64  \n",
      " 4   Age        400 non-null    int64  \n",
      " 5   Education  400 non-null    int64  \n",
      " 6   Gender     400 non-null    object \n",
      " 7   Student    400 non-null    object \n",
      " 8   Married    400 non-null    object \n",
      " 9   Ethnicity  400 non-null    object \n",
      " 10  Balance    400 non-null    int64  \n",
      "dtypes: float64(1), int64(6), object(4)\n",
      "memory usage: 57.5+ KB\n"
     ]
    }
   ],
   "source": [
    "## checking for missing values\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Caucasian           199\n",
       "Asian               102\n",
       "African American     99\n",
       "Name: Ethnicity, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## let's see the number of categories in ethnicity\n",
    "df.Ethnicity.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Female    207\n",
       " Male     193\n",
       "Name: Gender, dtype: int64"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Gender.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "No     360\n",
       "Yes     40\n",
       "Name: Student, dtype: int64"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Student.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Yes    245\n",
       "No     155\n",
       "Name: Married, dtype: int64"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Married.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df.drop(columns = \"Balance\"),\n",
    "                                                df.Balance, \n",
    "                                                stratify = df.Married,\n",
    "                                                random_state =42, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One Hot Encoding the Categorical Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "## instantiate ohe\n",
    "## note that in this case we know the categories very well.\n",
    "## import\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "## instantiate\n",
    "ohe = OneHotEncoder(categories= [[\"Caucasian\", \"Asian\", \"African American\"], [\"Female\", \" Male\"], [\"No\", \"Yes\"], [\"Yes\", \"No\"]],\n",
    "                    drop = [\"Caucasian\", \"Female\", \"No\", \"No\"], sparse = False,)\n",
    "\n",
    "## fit model (learn categories in train and plan how to convert them one hot encoded columns)\n",
    "ohe.fit(X_train[['Ethnicity', \"Gender\", \"Student\", \"Married\"]])\n",
    "## transform X_train data. Result is a numpy array.\n",
    "categorical_train = ohe.transform(X_train[['Ethnicity', \"Gender\", \"Student\", \"Married\"]])\n",
    "## concact the categorical variables with the rest of the data\n",
    "train = np.hstack((X_train.select_dtypes(exclude = \"object\" ), categorical_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(320, 11)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "## note that we should make the similar transformation to the test data too.\n",
    "## Remark: Never fit a transformer to your test data. Only transform!!\n",
    "categorical_test = ohe.transform(X_test[['Ethnicity', \"Gender\", \"Student\", \"Married\"]])\n",
    "test = np.hstack((X_test.select_dtypes(exclude = \"object\"), categorical_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80, 11)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['x0_Asian', 'x0_African American', 'x1_ Male', 'x2_Yes', 'x3_Yes'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ohe.get_feature_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting a Linear Regression (Baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "## import \n",
    "from sklearn.linear_model import LinearRegression\n",
    "## instantiate\n",
    "lr = LinearRegression()\n",
    "## fit \n",
    "lr.fit(train, y_train)\n",
    "## predict\n",
    "y_train_pred = lr.predict(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -7.691,   0.181,   1.227,  15.466,  -0.671,  -1.419,   7.498,\n",
       "        -2.283,   8.193, 433.656,  -5.428])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.set_printoptions(suppress=True, precision=3)\n",
    "lr.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9532149163845625"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## R_squared score\n",
    "lr.score(train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "## import\n",
    "from sklearn.linear_model import Ridge\n",
    "## instantiate\n",
    "ridge = Ridge(alpha = 10, normalize = True) ## note that we should normalize/standardize data if you are using regularization\n",
    "## fit\n",
    "ridge.fit(train, y_train)\n",
    "## predict\n",
    "ridge_train_pred = ridge.predict(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.421,  0.014,  0.207,  2.757, -0.059,  0.147,  1.417,  5.896,\n",
       "       -3.954, 40.557,  0.194])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## coefficients\n",
    "ridge.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2595672954223692"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## score\n",
    "ridge.score(train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.   ,  0.   ,  1.397,  0.   , -0.   ,  0.   ,  0.   ,  0.   ,\n",
       "       -0.   ,  0.   , -0.   ])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## import\n",
    "from sklearn.linear_model import Lasso\n",
    "## instantiate\n",
    "lasso = Lasso(alpha= 10, normalize= True)\n",
    "## fit\n",
    "lasso.fit(train, y_train)\n",
    "## predict\n",
    "lasso_train_pred = lasso.predict(train)\n",
    "## coefficients\n",
    "lasso.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9529584577282092"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## score\n",
    "\n",
    "lasso.score(train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some Important Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions\n",
    "\n",
    "\n",
    "\n",
    "__Q.__ Should I do normalization for Lasso or Ridge?\n",
    "\n",
    "A. Yes? Why?\n",
    "\n",
    "__Q.__ When we know that Ridge and Lasso is better than vanilla linear regression?\n",
    "\n",
    "A. High variation in your model --> Colinearity and too many variables.\n",
    "\n",
    "__Q.__ How do we know whether we should choose Lasso or Ridge?\n",
    "\n",
    "A. Most of the time they perform very similar but Lasso has the feature selection property, ridge doesn't have this.\n",
    "\n",
    "__Q:__ How do we choose $\\lambda$?\n",
    "\n",
    "A. [sklearn gridsearch](https://scikit-learn.org/stable/modules/grid_search.html#grid-search) for small models or random grid search for bigger models.\n",
    "\n",
    "Or check-out: \n",
    "\n",
    "[Sklearn - LassoLarsIC](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LassoLarsIC.html)\n",
    "\n",
    "[Sklearn - LassoCV](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LassoCV.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Miscellaneous"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "## import\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "## instantiate\n",
    "scaler = StandardScaler()\n",
    "## fit\n",
    "scaler.fit(train)\n",
    "## transform\n",
    "scaled_train = scaler.transform(train) \n",
    "## Apply to test: !! Don't fit only transform\n",
    "scaled_test = scaler.transform(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observing the effect of Regularization in Polynomial Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After adding higher order terms:  (320, 4368) (80, 4368)\n"
     ]
    }
   ],
   "source": [
    "## import\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "## instantiate -- with desired degree. \n",
    "poly = PolynomialFeatures(degree=5)\n",
    "## fit\n",
    "poly.fit(scaled_train)\n",
    "## transform\n",
    "Xp_train = poly.transform(scaled_train)\n",
    "## apply to test: !! Don't fit only transform\n",
    "Xp_test = poly.transform(scaled_test)\n",
    "print('After adding higher order terms: ', Xp_train.shape, Xp_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Selection with Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 793460.484187546, tolerance: 5257.7543359375\n",
      "  positive)\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1722184.8873493765, tolerance: 5440.306824609375\n",
      "  positive)\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1774828.4260413772, tolerance: 5469.784321484375\n",
      "  positive)\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1324537.1780131762, tolerance: 5191.286458984375\n",
      "  positive)\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1228092.101837951, tolerance: 5195.538730859375\n",
      "  positive)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "## import\n",
    "from sklearn.model_selection import cross_validate\n",
    "## note that cross-validate is a function so we don't need to instantiate it\n",
    "\n",
    "\n",
    "## chose a model for validate\n",
    "lasso = Lasso(alpha = 10)\n",
    "\n",
    "cv = cross_validate(estimator=lasso, X=Xp_train, y=y_train, cv = 5, return_estimator= True, return_train_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type of cv object is <class 'dict'>\n",
      "Keys of cv object is dict_keys(['fit_time', 'score_time', 'estimator', 'test_score', 'train_score'])\n"
     ]
    }
   ],
   "source": [
    "## cv is an dict object\n",
    "print(\"Type of cv object is\", type(cv))\n",
    "print(\"Keys of cv object is\", cv.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.973 0.976 0.974 0.974 0.972]\n",
      "[0.719 0.689 0.874 0.961 0.946]\n"
     ]
    }
   ],
   "source": [
    "print(cv['train_score'])\n",
    "\n",
    "## note that even though the name is test_score this is in fact validation score\n",
    "print(cv['test_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_experiment(X, y, num_iter = 5, \n",
    "                     models = ['ols', 'ridge', 'lasso'], alpha= 10, \n",
    "                     complexity = 'simple', degree = 3):\n",
    "    \"\"\"\n",
    "    parameters:\n",
    "    _________________________\n",
    "    num_iter: int, number of times fit the models to test data each time with different splitting. \n",
    "    note that for each iteration we split the data random train and test parts.\n",
    "    models: list, list of models that we want to use. Options are 'ols' for simple linear regression\n",
    "    'ridge' for ridge regression and 'lasso' for lasso regression.\n",
    "    alpha: float, alpha parameter for ridge and lasso algorithms. Recall that higher values of alpha \n",
    "    leads to more regularization.\n",
    "    complexity: str, either 'simple' or 'polynomial'. We either use the original dataset or \n",
    "    a dataset with polynomial powers generated. \n",
    "    degree: int, if complexity is polynomial then degree is the degrees of polynomials to be generated.\n",
    "    return: dict, it returns a dictionary with trained models as values and the 'complexity' parameters as keys.\n",
    "    \"\"\"\n",
    "    \n",
    "    x_axis = np.arange(num_iter)\n",
    "    y_ols_test = []\n",
    "    y_lasso_test = []\n",
    "    y_ridge_test = []\n",
    "    sample_models = {}\n",
    "    for i in range(num_iter):\n",
    "        \n",
    "        if complexity == 'simple':\n",
    "            ## split train_test \n",
    "            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)\n",
    "        elif complexity == 'polynomial':\n",
    "            ## Create higher order terms\n",
    "            poly = PolynomialFeatures(degree=degree)\n",
    "            Xp = poly.fit_transform(X)\n",
    "            ## test-train split\n",
    "            X_train, X_test, y_train, y_test = train_test_split(Xp, y, test_size = 0.2)\n",
    "\n",
    "\n",
    "        ## Standard scale mean = 0, variance = 1\n",
    "        sd = StandardScaler()\n",
    "\n",
    "        sd.fit(X_train)\n",
    "\n",
    "        X_train = sd.transform(X_train)\n",
    "\n",
    "        X_test = sd.transform(X_test)\n",
    "\n",
    "        ## Be careful about the leakage\n",
    "\n",
    "        ## Vanilla model\n",
    "        if 'ols' in models:\n",
    "            lr = LinearRegression()\n",
    "\n",
    "            lr.fit(X_train, y_train)\n",
    "            \n",
    "            sample_models['ols'] = lr\n",
    "\n",
    "            test_score = lr.score(X_test, y_test)\n",
    "            train_score = lr.score(X_train, y_train)\n",
    "\n",
    "            y_ols_test.append(test_score)\n",
    "\n",
    "    #       print('test score OLS is %.2f and train score is %.2f'%(test_score, train_score))\n",
    "\n",
    "        if 'ridge' in models:\n",
    "            ## Ridge in the simple setting\n",
    "            ridge = Ridge(alpha = alpha, max_iter= 10000)\n",
    "            ridge.fit(X_train, y_train)\n",
    "            sample_models['ridge'] = ridge\n",
    "            y_ridge_test.append(ridge.score(X_test, y_test))\n",
    "    #         print('test score Ridge is %.2f and train score is %.2f'%(ridge.score(X_test, y_test),\n",
    "    #                                                             ridge.score(X_train, y_train)))\n",
    "\n",
    "        if 'lasso' in models:\n",
    "            ## Lasso in the simple setting\n",
    "            lasso = Lasso(alpha = alpha, max_iter= 10000)\n",
    "\n",
    "            lasso.fit(X_train, y_train)\n",
    "            \n",
    "            sample_models['lasso'] = lasso\n",
    "            \n",
    "            y_lasso_test.append(lasso.score(X_test, y_test))\n",
    "    #       print('test score Lasso is %.2f and train score is %.2f'%(lasso.score(X_test, y_test),\n",
    "    #                                                             lasso.score(X_train, y_train)))\n",
    "\n",
    "        i+=1\n",
    "    if 'ols' in models:\n",
    "        plt.plot(y_ols_test, label = 'ols')\n",
    "    if 'ridge' in models:\n",
    "        plt.plot(y_ridge_test, label = 'ridge')\n",
    "    if 'lasso' in models:\n",
    "        plt.plot(y_lasso_test, label = 'lasso')\n",
    "    plt.ylabel('R2 test score')\n",
    "    plt.xlabel('number of iterations')\n",
    "    plt.ylim((0.50, 0.99))\n",
    "    \n",
    "    plt.legend()\n",
    "    return sample_models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEGCAYAAABo25JHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nO3dd3gU5fbA8e9JoSX0UENVunQiNRRFJCBVFLwIiDQRAfXay++q2C8oIlVRRBQvonQUxAJSBCGhhF4DEiCFmpCQkPL+/pgNBgwQkuxOkj2f58nD7s7sO2eHZM+8dcQYg1JKKfflYXcASiml7KWJQCml3JwmAqWUcnOaCJRSys1pIlBKKTfnZXcAt8rPz89Uq1bN7jCUUipPCQkJOW2MKZPRtjyXCKpVq0ZwcLDdYSilVJ4iIseut02bhpRSys1pIlBKKTeniUAppdycJgKllHJzmgiUUsrNaSJQSik3p4lAKaXcnCYCpZRyc5oIlFLKzWkiUEopN6eJQCml3JwmAqWUcnOaCJRSys1pIlBKKTeniUAppdycJgKllHJzmgiUUsrNaSJQSik3p4lAKaXcnCYCpZRyc5oIlFLKzWkiUEopN6eJQCml3JwmAqWUcnOaCJRSys1pIlBKKTeniUAppdycJgKllHJzmgiUyi1OhMAPz0DofLh03u5olBvxsjsAl0m6ZP3rXdjeOJTKyNY5VhJITYEtn4GHN1RvB3W7Qe37oGg5uyNU+Zj71Ai2fQ0TasMPz8KpULujUcqSnAjLnoKlY6BqG3j2AAz9BVo+DmePwPKn4YPa8Hln+GMKnDtqd8QqHxJjjN0x3JKAgAATHBx86288EQKbZsCeJZCSCBWbQNNBUP8BKFQs5wNV6mZiTsH8gRC+Bdo8BR3/Ax6ef283BqL2wN7lsHcZRO60Xi/fAOr2gDrdoGxdELEnfpWniEiIMSYgw21ukwjSXDoHod/B1i8hchd4F4E7eltJoXIL/aNypdRU6/+gVHUoWNTuaFzr2EaYPwgux0GvaXBHr5u/52wY7HMkheObAQOlbreaj+r2gIpNwcN9Kvnq1mgiyIgxcHKr1Ta783u4fBH8alkJodG/wMcv+8dQGYuNgO1zYetXcC4MivlD90lQs5PdkTmfMVYfwMoXoURVeGiudVV/q2IjYN8PVmIIWwupyVC0glVLqNvNamby9M75+FWepYngZhIvwp7FVlI4/qfVUVfnPisp3HaXXmXlhJRkOPSLVRM78BOYFKjW1rqSDf4covdB4wHQ+W0oXMLuaJ0j6RIs/zfs+AZqBUHvT3Lms146BwdWwd6lcOhXSL4EhUtC7a5WYrj9Lh0koexLBCISBEwCPIHPjDHvXbO9KjALKAOcBQYYY8JvVKZTEkF6UfushLDjf3DpLBSvAk0GQJOHoXgl5x03vzobZnXUb58LsafApyw07m8l2dK3W/skJ8Lv78P6j8C3rFU7qNXZ3rhz2vm/4NsBcGoHtH8R2r/gnAuMy/Fw+Fer+Wj/Ski8AN4+UPMeK+nW7ASFiuf8cfOr+LNWjatoBajcPE83HduSCETEEzgAdALCgS3Av4wxe9Lt8x2w3BjzpYjcDTxqjBl4o3KdngjSJCdaVe+tc+DIahAPqHGP9QVWK0ir3TeSnGg1WWydA0fWpDt3j1hf8Nc7dye2wuJREL0XGvWHoHesK9u87sjv8P2jkJIE938Ktbu45rjJl+HoOuv/Yt8PcDHSqu3e1uHvYam+ZVwTS16R1kF/4CfrJ3wzmFRrW4mq0OBBaNgXytS2N84ssCsRtAJeN8Z0djx/CcAY8266fXYDnY0x4SIiwAVjzA2H8LgsEaR37qh1Vbvta8dVbRnrqrbJIPCr4dpYcrOovY7a1Ly/a1NNB1rnKrO1qeRE+P2/sH6idZ67T4LaQc6N21mMgY1T4Of/WP1P/eba9/uSmmqNTtq71KotnD9mJejKLaFudysxlKhiT2x2S7oEYevgwEo4uAouHLder9AIana2LmLOhUHot9aFjUm1tjXoC/X7QLEKtoafWXYlggeAIGPMMMfzgUALY8zodPt8A/xpjJkkIvcDCwA/Y8yZa8oaAYwAqFKlSrNjx445JeabSkm2qt1b58D+FVY7d9VAq5ZQr4d7tsMmXoTdi6xzEr455/pXTm6DxU9A1G5o+BAEvQtFSuVs7M50Oc6aG7BrAdTrCT2n5p6RUcZYo7X2LrOGpkbttl6v0MhKCnW6W1e8ebgZ5KYuhFtX/AdXWTW25EtWE9ptHaxaa817M/6Cj42E3Qut2d8ntwJiTfxr2M86d7l4KLpdieBBrKv99ImguTFmTLp9KgJTgOrAWqAPcIcx5sL1yrWlRpCR2Eir02/rHGviT8HiVpWx6SCo0NDu6JzrqhFXC+ByrHNGXCVfhrXjYf2HUKQ0dPsI6nTNmbKd6ewRmDfAauLq+B9rjkBu/lI9c/jvYanhW6zXSlSBCo2t3+Xyjax/i5a3N87sSE2B8OC/r/ojd1mvl6hqNfXWute6qPMulPkyTx+CnfOtpHAuDLwKWWU17As1OoFXAed8lizKtU1D1+zvC+wzxtywDSHXJII0xsDR9daXYtpktQqNrS/FBg/m6iuEW3bpnPVLv3WO9YfkVRjq3+/8ORindlh9B5G7rOp4l/dzb+3g4M+wYKjV7NLnc6jR0e6Ibk3MSas/4eg6awb+ubC/t/mUdSSGBlC+oVWDKFk9946qu3TOGkV1cJX1/3LpLIgnVGllffHXCrIuYLL7e2uMNWE19FvYtRDiT1t9W/V6WUmhcstccY7sSgReWJ3FHYETWJ3F/Y0xu9Pt4wecNcakisjbQIox5j83KjfXJYL08uNktRsmugdcNwIl+TKs+wDWTYDCpaDbRKtdO7dITbXiW/02lKsPD30NJavZHVX2JVyAiF0QEQoRO63kEL3XmrcAUKAolK+fLjk0hDJ17bkaNgai9/991f/XJqv5tnApq6mn1r1w+93OHYCQkmT1I4R+ayXUpHirr6zBA1ZSyMqckRxi5/DRrsBHWMNHZxlj3haRcUCwMWapox/hXcBgNQ09YYxJvFGZuToRpMkPk9UybPp60NH01ci+uE6FOmoHO63lQbqOt792kBADix+3mlca9LU6uAsUsTcmZ0pOtAYGRIRa/x8RO62fpDhru4c3lK1jNSmVb2Alh3L1nVM7TkqwLlQO/mQlgPN/Wa+Xa/D3Vb9/s6uX7nCVxIuw/0erFn34NysplWtg/R3VfwCK+7s0HJ1QZqeMJqtVbmGNl/fxs9q+036uPPezvtxcPUQ1NcUx6St9Z3gb68u/bo/c8+WWkgTrPrT6DwqXgPs+tDrr7RB9AL592Gpn7/w2tBiZN2t+2ZWaal0wROxwJAdHkog//fc+pW6zag3lG1gXE+UbZm1V1ZiT6Tp611hX3V6F4bb2f3f05rY5Pxej/+5kPhEMCFQLtGoJdXu4ZBKlJoLcIm2y2olgiDsN8Wcg4Qbrzhcqni4xlAaf9I+vSRo+flDAN2tfQueOpRsee9IqM23Sl1/NrH9eZ4vYZV2JR4TCHfdD1wnWOXKVvcth0UjwKgh9v7T+sNXfjLGWwrhSc9hh1RzSr6DqW+7vJqW05qVr+x1SU6w5JmlX/RGOxfeKV7a++GsFWec+r4zaO3MYdn5nJYWzh8GzoPU5Gva1kphXQaccVhNBbpaSZPUtpCWGeMe/cWeu/zzlcsZleRa4Jmlcm0TSPS9SCv7aCCFfWldVYHVsNn3E+sPKZSMerislyZqR/Pv7VuK874PMLeCWHakpsPodq7/Cvxn0/crl1fw87dJ5qw8tfc0hep9VAwVHv4OjSSnhgtXRG3/aMe+hheOqv3PeX3k1rQk59DvY9T3ERVu/w/V6Wk2MVdvkaCezJoL8xBirzyHutDX9/UqiSJdIrk0iCdcdjQvFKjkmfT0MJSq77nPktMjdVu3g1A5rtMZ9HzinL+bSOVgwHA79DE0GWrWQWxlyqDKWlGB1QqdPDpG7rIubmp0cE7s62t8f5CwpyRC2xkoKe5dZ/S3FKkGDPlZSKF8/24fQRODuUpIyThqlqjsmfdnQkeYMKUmwYZJVOyhY1FE76J1z5UfuhnkPW5ORuv4Xmj2at69Ic7tUx9IOuWDopUtdjrP66ELnWxNYU5OhbD2r6ahB3yzXPjURKPcSuQeWjLJmJ9frCV0/yP6aOju/t2YKFyoOfedYC5Ap5Wxxp62Z+6HzrZn7930Adw7LUlGaCJT7SUmGPz6GNe9anej3TbA6lG/1Cj4lGX55zVozqEorePBLvX+wssfZMKtpLItzd26UCNyszqXchqcXtP03PLbOagL7foh1W8iLUZkvI+40fN3bSgLNR8CgpZoElH1KVXfaBE5NBCp/K1sHhqyCe96wbt4ytbnVzHOzmvDJbfBpB+uWkL2mWxPX8spIKqVukSYClf95ekHgUzBynXWP3wVDrZvExEZmvP/2b+Bzx41xhqy05lQolY9pIlDuo0xtGLoKOr1pjU2f2tzqhEurHSRfhh+etYahVmkBI9ZAxSZ2RqyUS2giUO7FwxPajIWR6631nxYOh3n9rfkHc3rAlpnQegwMWJQ31oRSKgd42R2AUrYoU8tq9tk0HX5701oczLsIPDDLuuuUUm5EE4FyXx6e0Hq0taTGn9MhYAiUu8PuqJRyOU0ESvnVsCbqKOWmtI9AKaXcnCYCpZRyc5oIlFLKzWkiUEopN6eJQCml3JwmAqWUcnOaCJRSys1pIlBKKTeniUAppdycJgKllHJzmgiUUsrNaSJQSik3p4lAKaXcnCYCpZRyc5oIlFLKzWkiUEopN6eJQCml3JwmAqWUcnOZTgQi4uPMQJRSStnjpolARFqLyB5gr+N5IxGZ5vTIlFJKuURmagQTgc7AGQBjzA6gnTODUkop5TqZahoyxhy/5qUUJ8SilFLKBplJBMdFpDVgRKSAiDyLo5noZkQkSET2i8ghEXkxg+1VRGS1iGwTkVAR6XqL8SullMqmzCSCkcATgD8QDjR2PL8hEfEEpgJdgHrAv0Sk3jW7vQrMN8Y0AR4CtO9BKaVczOtGGx1f5gONMQ9noezmwCFjzBFHWfOAnsCedPsYoJjjcXHgZBaOo5RSKhtuWCMwxqRgfXlnhT+Qvm8h3PFaeq8DA0QkHPgRGJNRQSIyQkSCRSQ4Ojo6i+EopZTKSGaahjaIyBQRaSsiTdN+MvE+yeA1c83zfwGzjTGVgK7AVyLyj5iMMZ8aYwKMMQFlypTJxKGVUkpl1g2bhhxaO/4dl+41A9x9k/eFA5XTPa/EP5t+hgJBAMaYjSJSCPADojIRl1JKqRxw00RgjLkri2VvAWqKSHXgBFZncP9r9vkL6AjMFpG6QCFA236UUsqFMjOzuLiIfJjWRi8iH4hI8Zu9zxiTDIwGfsIabjrfGLNbRMaJSA/Hbs8Aw0VkB/A/YLAx5trmI6WUUk4kN/veFZEFwC7gS8dLA4FGxpj7nRxbhgICAkxwcLAdh1ZO8OuxX2lYpiFlimjfj1LOJCIhxpiAjLZlprP4dmPMa8aYI46fN4DbcjZE5Y7WHF/DU2ue4v82/J/doSjl1jKTCC6JSGDaExFpA1xyXkjKHcQlxfH2n29TwKMAG05uICQyxO6QlHJbmUkEjwNTReSoiBwFpmDNNs5zouJ1MFJuMWXbFCLjIpl2zzTKFC7D5G2T0e4hpexx00RgjNlujGkENAQaGmOaOFYgzVNm7ZrF/UvvJ+xCmN2huL2d0TuZu3cu/Wr3o0WFFgxvOJyQyBA2ndpkd2hKuaXMjBp6R0RKGGNijDExIlJSRN5yRXA5qVOVTniKJ4//8jinL522Oxy3lZSaxBsb36BMkTI82fRJAPrU7EMFnwpuXys4eO4gL6x9gci4SLtDUW4mM01DXYwx59OeGGPOYc0CzlMqF6vM1I5TOZtwlid+fYL4pHi7Q3JLX+35iv3n9vNyi5fxLeALQAHPAoxsNJKdp3fye/jvNkdoD2MMb256kx/DfmToqqHajKlcKjOJwFNECqY9EZHCQMEb7J9r1ferz/h249l3dh/P/v4syanJdofkVo7HHGf69ul0rNKRjlU6XrWtx+09qFK0ClO2TSHVpNoUoX1+/etXtkVto1/tfkTHRzP0p6FEx+vcSuUamUkEXwO/ishQERkC/MzfcwrynPaV2/NKi1dYd2Idb216y62bIlwp7YrX08OTl5q/9I/tXh5ejGo8iv3n9rPq2CobIrRPUkoSE0MmUqNEDV5s/iIzOs0gMj6SoauGajOmconMdBb/F3gLqAvcAbzpeC3P6lu7L8MbDGfBwQXM3DnT7nDcwvIjy9l4aiNPNn2Scj7lMtwnqFoQNUrUYOq2qW5VW/t2/7f8FfsX/272b7w8vGhStgnT75lORFwEw34apslAOV1mOot9gFXGmGeBT4GCIuLt9MicbEyTMXS7rRuTt01m6eGldoeTr51LOMf4LeNpWKYhfWv1ve5+nh6ePNH4CY7GHOXHsB9dGKF9LiReYEboDFpVaEWg/5XpOjQr14ypHadyMu4kw1cN58ylMzZGqfK7zDQNrQUKiYg/8AvwKDDbmUG5gogwrvU4WlRowWsbXuOPk3/YHVK+NSF4ArGXY3mt1Wt4enjecN+OVTpSt1Rdpm2fRlJqkositM+noZ8SkxjDMwHPIHL1yu13lr+TqR2nEh4bzvCfh3M24axNUar8LjOJQIwx8cD9wGRjTG+sW0/med6e3kzsMJHqJarz7zX/Zv/Z/XaHlO9sOrWJpYeX8mj9R6lVstZN9xcRxjQZw4mLJ1h0cJELIrTP8djjfLPvG3rV6EXtUrUz3OfO8ncyueNk/or5i+GrhnMu4ZyLo1TuIFOJQERaAQ8DPzhey8x9DPKEogWKMq3jNHy8fRj1yygi4iLsDinfSEhOYNzGcVQpWoURDUdk+n2B/oE0LtOYT0I/ITEl0YkR2uujkI/w9vBmdJPRN9yvZYWWTL57MsdijjHi5xGcTzh/w/2VulWZSQRPAi8BixzLSN8GrHZuWK5V3qc80++ZTnxyPI//8jgxl2PsDilf+CT0E47HHuc/rf5DIa9CmX5fWq0gKj6K7/Z/58QI7bM9ajurjq1i8B2DKVuk7E33b1WxFR/f9TFHzh9hxM8juJB4wQVRKneRmVFDa40xPYwx7zueHzHGjHV+aK5Vq2QtPrrrI47GHOWp1U9xOeWy3SHlafvP7mf2rtn0vL0nLSq0uOX3N6/QnBYVWjBz58x8N/nPGMP44PGUKVyGwXcMzvT7Wvu3ZtLdkzh0/pAmA5WjMlMjcBstKrTgzTZvsiViC69ueNUtJzblhJTUFMZtHEfRAkV5NuDZLJczuvFoziac5Zt93+RgdPb76dhPhEaHMqbJGIp4F7ml9wb6B/LRXR9x8NxBRv48UmuvKkdoIrhGt9u68WTTJ1kRtoJJWyfZHU6e9O3+bwk9HcrzzZ+nRKESWS6ncdnGtKvUji92fUHs5dgcjNA+l1Mu81HIR9QqWYset/e4+Rsy0K5SOyZ2mMi+c/sY+fPIfHNulH0yM4+gTWZey0+G1h9K31p9mbVrFvP2zbM7nDwlIi6CSVsn0bpia+6rfl+2yxvdeDQxl2P4as9XORCd/f6373+cuHiCZwKeuelQ2htpX7k9H7b/kL1n9zLyl5FcvHwxB6NU7iYzNYLJmXwt3xARXmrxEu0rtefdze+y+q981TfuVO/8+Q6pJpVXW776j3HxWVG3dF06Ve3EnD1z8vxomfMJ5/kk9BPa+LehdcXW2S7vrip3MaH9BPac3sPjvzxOXFJcDkSp3NF1E4GItBKRZ4AyIvLvdD+vA1m/lMkjvDy8+G+7/1KvVD2eX/s8odGhdoeU6/167FdWH1/NqMajqFy0co6V+0Rja7XYWbtn5ViZdvgk9BPikuJ4ptkzOVZmxyodGd9+PDtP79RkoLLsRjWCAoAv1pyBoul+YoAHnB+a/Yp4F2FKxyn4FfZj9K+j+SvmL7tDyrViL8fyzp/vUKdUHQbWG5ijZd9e4nbuu+0+/rf3f3l23Z1jMceYt28evWv0pmbJmjla9j1V7+G/7f5LaHQoo34Zle9GWSnnu24iMMb87rhRfUtjzBuOx28CnxljDrosQpuVLlya6fdMx2B4/JfHdZr/dUzaOonTCad5rdVreHnk/HzDUY1GkZSaxGc7P8vxsl3ho5CPKOBZ4KaTx7Lq3mr38l7b99gevV3vt6FuWWb6CN4VkWKOxef2APtF5Dknx5WrVCtejcl3TyYyPpIxv47hUvIlu0PKVbZHbWf+/vn0r9Of+n71nXKMysUq06tGL+bvn8+pi6eccgxnCYkM4Ze/fmFI/SH4FfZz2nGCqgfxbuC7bI3aypjf9PdUZV5mEkE9Y0wM0Av4EagC5GzdPw9oXLYx77d9n52nd/LC2hdISU2xO6RcISnFuvVkeZ/yjGkyxqnHeqzhY4DV1p5XpJpUJmyZQNkiZRl0xyCnH6/rbV15O/BtgiODGfPbGBKSE5x+TJX3ZSYReDuWne4FLDHGJAFueTeXjlU78mLzF1l9fDXvbn5Xb2oDfLH7Cw6dP8SrLV+95clRt6qCbwUerPUgiw8tzjP9NSvDVrLrzC7GNhlLYa/CLjlmt9u68Vabt9h8ajNjfxuryUDdVGYSwSfAUcAHWCsiVbE6jN1S/7r9GXzHYL7d/y1f7P7C7nBsdfTCUT7Z8Qmdq3WmXaV2Ljnm8IbD8fbwZvqO6S45XnYkpiQyaesk6pSqQ/fbu7v02N1v786bbd5k06lNPLn6yXy9eJ8zRMVHsejgIp5Z8wxt57Vl8MrBhESG2B2W09y0V88Y8zHwcbqXjonIXc4LKfd7utnTRMRFMDFkIuWLlKfrbV3tDsnljDGM2zSOgp4FebH5iy47rl9hP/5V91/M3jWbYQ2GcXuJ21127Fs1d+9cTsadZFybcXiI6yfx96zRk1STyn/++A9Prn6SSXdNoqBnnrzduNMlpSSxPXo7606sY8OJDRw4dwCAsoXL0sa/DZtPbWbwysG0qdiGMU3GcIffHTZHnLNumghEpBzwDlDRGNNFROoBrYDPnR1cbuUhHrwd+DbRl6J5ZcMr+BX2o3mF5naH5VKLDy1mS8QWXmv1mlM7QDMy5I4hzN8/n6nbp/Jhhw9deuzMOptwlpmhM2lXqV2WFt3LKb1r9ibVpPL6xtd5evXTfHSXNXpJwYmLJ9hwYgPrT6znz1N/Ep8cj5eHF03LNuXpZk/TpmIbapWshYiQkJzAt/u/5bOdn/HQDw/RsUpHRjceTY2SNez+GDlCbtbOLSIrgC+AV4wxjUTEC9hmjGngigCvFRAQYIKDg+049D9cSLzAoBWDiI6P5ssuX+b4+PDc6sylM/RY3IMaJWrwRdAXtlztTt0+lRk7ZjC/23zqlq7r8uPfzDt/vsP8/fNZ2GMht5W4ze5w+O7Ad4zbOI72ldrzYYcP3TIZJKYkEhwRzPoT69lwcgNhF8IAqOhTkUD/QNr4t6FFhRb4ePtct4yLly/y1d6vmLN7DnFJcdx3232MajSKysVybgKls4hIiDEmIMNtmUgEW4wxd4rINmNME8dr240xjZ0Q603lpkQAcPLiSQb8OABPD0++7vL1dW/Mnp+8sPYFfj72M993/962L7nYy7EELQiicdnGTO041ZYYrifsQhj3L7mfPrX68GrLV+0O54r5++fz5qY36VC5Ax+2/xBvzzx/6/EbMsZwLOYYG05aV/3BEcEkpCRQwKMAd5a/kzb+bQj0D6RasWq3vBzK+YTzfLH7C77Z+w3Jqcn0rtmbEQ1HUN6nvJM+TfbdKBFkZuZPnIiUxjFSSERaAroQukNF34pMu2caj6x4hFG/juLLoC/xLeBrd1hOs/7Een4M+5FRjUbZeqVbtEBRHq3/KJO2TmJ71HYal7XluiRDE0MmUtCrII83etzuUK7St3ZfUkwK7/z5Ds+tfY7x7cfj7ZG/kkF8UjybIzaz/sR61p9Yz4mLJwCoVqwafWr1IdA/kGblmmV7BFeJQiV4utnTDKg7gJk7Z/Ldge9YcmgJ/er0Y1iDYZQqVConPo7LZKZG0BRrkbn6wC6gDPCgMWaH88P7p9xWI0jzx4k/eOLXJwgoH8C0jtPy5dVWfFI89y+9nwKeBfi++/e2Ny/EJ8XTZWEXapasyWf35o4Zx1sitjDkpyE82fRJhjUYZnc4GZq7dy7vbX6PTlU78X679/N0MjDGcOj8oStt/SFRISSnJlPYqzAtyrcg0D+Q1v6tc3Ttq4ycuHiCGTtmsPTwUgp6FmRgvYE8cscjFCtQzKnHvRXZbRoqCKQAtQEB9gMexhhbxqPl1kQAVgfq/234P3rc3oO32ryVI6tv5iYfBH/A7N2zmR00m2blmtkdDgBf7fmK/275L5/f+7ntHfapJpWHlj/EucRzLOu17JZuz+lqaeft3qr38n67952yLIizxFyO4c9Tf1656o+KjwKgRokatPVvSxv/NjQp28SWC5WwC2FM2z6NlUdXUrRAUYbUH0L/Ov2dPscmM7LbNLTRGNMU2J2uwK1A0xyKL9/oVaMXp+JOMW37NCr4VHDaujJ22HNmD3P2zOGBWg/kmiQAVnPH7N2zmbxtMnPKz7E1+f5w5Af2nt3LO4Hv5OokADCw3kBr1nPwBDzWefBu23dzbTJINansO7vP6uQ9sYEd0TtIMSn4evvSqmIr66q/Yutc0T5fvXh1xrcfz9AGQ5mybQqTtk7iqz1fMbzBcB6s/WCuHb573f95ESkP+AOFRaQJVm0AoBhgf3rLpUY2HElEXASfhH5CeZ/yPFAr7y/UmpyazBsb36BkwZI81fQpu8O5SkHPgjzW8DHe3PQm60+sp22ltrbEkZCcwMfbPqZe6Xrcd1v2b8jjCo/c8QjGGD4I+QAR4Z3Ad2xNBsYYYi7HcCruFBFxEUTERRAaHcqGkxuuLPZYt1RdhtQfQqB/IA3KNMi1zVp1StVhSscpbI/azpRtU3h/y/t8uedLRjYcSc8aPXNd0r1RNJ2BwUAl4AP+TgQxwMuZKVxEgoBJWPcv+MwY89412ycCaZPTigBljTFZv7dhLoh9z9wAAB0wSURBVCAivNryVSLjI3lr01uULVLWZbNuneWbvd+w58wexrcfT/GCxe0O5x961+jNrF2zmLxtMoH+gbbUCr7e+zURcRG8E/iOLcNps2pw/cGkmBQ+2vqRNT+mzdvZunPajcQnxV/5go+Ij7jyOO2LPzI+8h8L5ZUoWILWFVsT6B9Iq4qtXD5nJbsal23MZ50/Y9OpTUzeOpnXN77OrF2zeKLxEwRVD8o1vyuZ6SPoY4xZcMsFi3gCB4BOQDiwBfiXMWbPdfYfAzQxxgy5Ubm5uY8gvfikeAavHMzRmKN80fmLPDsT8eTFk/Ra0os7y9/JlLun5Np+jyWHlvDqhleZ2GEi91S9x6XHPnPpDPctuo/m5Zvz8d0f3/wNudDM0Jl8vO1jut9mLU1xq8kgKSWJyPjIq77U03/JR8RFEHP56pVpBMGvsB/lfcr//VOk/FXP/Qr75Zovy+wyxvB7+O9M3jaZA+cOULNkTUY3Hs1dle9yyd9VtjqLs3HQVsDrxpjOjucvARhj3r3O/n8Arxljfr5RuXklEQCcvnSah394mISUBOZ2nUulopXsDumWGGMY/dtotkRsYXHPxVT0rWh3SNeVkppC76W98RRPvu/+vdOuajPy1qa3WHBgAQt7LqR68eouO25O+2THJ0zZPoWet/e8almMlNQUziScuepL/aqf+AjOXDqDuWYtyuIFi//jiz3ty76CbwXKFi6bL0fX3UyqSeWnoz8xdftUjsUco4FfA0Y3GU2rCq2cmhCy21mcVf7A8XTPw4EM59o7FrKrDvx2ne0jgBEAVapUydkoncivsB/T75nOwBUDefyXx/mqy1eUKJR3Wr5+OvYTa8PX8vydz+fqJADg6eHJqMajeO7351h5dKXL2umPnD/C9we+p2/tvnk6CQA81ugxUk0q03ZM46/YvxCEiLgIouKjSDbJV+1b2Ksw5X3KU8GnArVK1bryhV/OpxwVfCpQrki5XDFSJjfyEA+6VO9Cp6qdWHZ4GdN2TOOxnx/jzvJ3MrbJWFvmxDizRvAg0NkYM8zxfCDQ3Bjzj0XrReQFoFJG266Vl2oEaUIiQxixagT1Stdj5r0zc/2IErCWz+i5uCflfcozt+tcl15hZ1WqSeXBZQ+SkJzAkl5LXNIh98SvT7A1cis/3P9DnptEdD2f7fyMJYeWXN1sc82VfbECxXJtM2FecznlMt8d+I6ZoTM5k3CGtv5tGdNkTI4vnXKjGgHGmOv+YI0Quj2D1xve6H2OfVoBP6V7/hLw0nX23Qa0vlmZxhiaNWtm8qKVYStN/dn1zdOrnzbJKcl2h3NTr214zTT6spHZc3qP3aHckt+O/Wbqz65vFhxY4PRjbTy50dSfXd98vvNzpx9L5X9xl+PMzNCZpvU3rU392fXNv1f/2xw+fzjHygeCzXW+V6/bCyMifYF9wAIR2S0id6bbPDsTCWgLUFNEqotIAeAhYGkGx6kNlAQ2ZqLMPKtztc48G/AsPx/7mZfXv8yeM3ty7Y1tgiOCWXBwAYPqDcqVC7rdSIfKHWjg14AZO2ZwOeWy046TkprCB8EfUNGnIg/Xfdhpx1Huo4h3EYY1GMaKPit4rOFjrD+xnt5LevPK+lcIjw136rFv1B3/MtDMWIvLPQp8JSL3O7bdtE5ojEkGRgM/AXuB+caY3SIyTkR6pNv1X8A8k1u/FXPQoHqDGN5gOKuOrqLf8n50X9ydKdumcPj8YbtDu+JyymXe2PgG/r7+jGw00u5wbpmIMLrJaE7FnWLBwVse7JZpy48sZ9/ZfTzZ9MlcO0lI5U3FChRjdJPRrOizggF1B7AybCXdF3fnrU1vXZlFndOu20cgIjtNuqWmRaQCsBz4EhhsrNnGLpcX+wiudT7hPL/89Qsrw1ayJXILqSaVGiVq0KV6F4KqBVGlmH0d4tO2T2P6junMuGcGbfzb2BZHdhhjePSnRzkWc4wf7/8xx28ReSn5Et0WdaNckXLM7TpX28qVU0XGRfJp6KcsPLiQ5+58jv51+2epnCwNH3UM5xxojDmc7rWiwGIg0Bhjy2VQfkgE6Z2+dJpVR1ex8uhKtkVtA6Be6Xp0qdaFztU6U8G3gstiOXL+CH2W9aFztc681/a9m78hFwuJDGHwysE80+wZBtcfnKNlz9gxg6nbp/Jl0Jc0LacrrSjXOB57nHJFymV5DaWsJoJGQLwx5uA1r3sDfY0xc7MUTTblt0SQXkRcBD8d/YkVYSvYfcZa2qlxmcYEVQ+ic7XOTp1VmWpSeXTloxy+cJglPZdQunBppx3LVUb+PJLdZ3azss/KG95s5FacvnSargu70qZiGybeNTFHylTKFW6UCK7bR2CM2XFtEnBIzbHI1FXK+5TnkTseYV63efzY+0fGNhlLXHIc721+j47fdWTYT8P47sB3nE84n+PHXnBwAVujtvJswLP5IgkAjG4ymvOJ5/l6z9c5VuaUbVNISkniqWa5a80lpbLjRjWCYsATWBPDlgI/Y3X+PgtsN8b0dFWQ6eXnGsH1HD5/mJVHV7IybCVHY47iJV60rNiSoGpB3F3lbooWKJqt8qPjo+m5uCd1S9fls3s/y1dt3mN/G0twRDAr+qzI9jpJB88d5IFlD9C/Tn9eaP5CDkWolGtktWloCXAOa1hnR6whngWAJ40x250U6025YyJIY4xh/7n9rAhbwcqwlZyMO4m3hzdt/dsSVD2I9pXaZ2k25zNrnmHN8TUs7LmQqsWqOiFy+xw4d4AHlj7AsAbDGNt0bLbKGvnLSEKjQ/mx9495aoa4UpD1JSZuSxs1JCKfAaeBKsaYWCfEqDJBRKhTqg51StXhqaZPsfP0TlaErWDV0VX8dvw3CnsVpn2l9gRVCyKwUmCmhjWuOb6GVcdWMbbJ2HyXBABqlaxFULUgvt77NQ/XfTjLzV5/nPiDDSc28GzAs5oEVL5zoxrB1vRDRK99bhd3rhFcT6pJZWvkVlYeXcmqo6s4l3gOH28fOlbpSOdqnWlVsVWG67bHJcXRa0kvfL19md9tfr5dACzsQhi9lvRiQN0BPHfnc7f8/pTUFB5c/iDxSfEs7bXU9lt0KpUVWa0RNBKRtHVjBesGNTGOx8YYk3tuxunmPMSDgPIBBJQP4MXmL7L51GZWHl3JL3/9wtLDSylesDj3VLmHLtW7EFAu4Mq6QVO2TSEyLpLxXcbn2yQA1l2jut/WnXn75jGo3iDK+ZS7pfcvObyEg+cOMr79eE0CKl9y2qJzzqI1gsxLSknij5N/sOLoClb/tZr45HhKFyrNvdXupW6purz2x2v0q92PV1q+YneoTnfi4gm6LepGn5p9eLXlq5l+X3xSPN0WdaOib0W+6vJVvupIV+7FrmWolc28Pb1pX7k97Su3JyE5gXUn1rEibAULDy4kMSWRskXK8mTTJ+0O0yX8ff3pU7MPCw4uYPAdgzN9b4jZu2cTfSmaDzt8qElA5VuaCNxEIa9CdKraiU5VOxGXFMe6E+uoXqw6vgV87Q7NZYY3GM6ig4uYsWMGbwW+ddP9o+KjmL17NvdWvdeWNeKVcpX8cQ84dUt8vH0IqhZE7VK17Q7Fpcr5lKNfnX4sO7KMsAthN91/yrYpJKXq5DGV/2kiUG5laP2hFPQsyPTt02+43/6z+1l8aDH96/SnctHKLopOKXtoIlBupXTh0gyoO4AVR1ew/+z+DPcxxjAheAJFCxRlRMMRLo5QKdfTRKDcziN3PEJR76JM3T41w+3rT6xn06lNjGw0MtvLUiiVF2giUG6neMHiDLpjEKuPr2bX6V1XbUtOTeaD4A+oUrQKD9V+yKYIlXItTQTKLQ2sN5ASBUswZduUq15fdGgRhy8c5ulmT+frSXZKpaeJQLklH28fhtYfyoaTGwiJDAGsJTembJtC07JN6Vilo80RKuU6mgiU2+pXpx9+hf2YvG0yxhhm7ZrF2YSzPBPwjE4eU25FE4FyW4W9CjOi4QhCIkNYfGgxc3bPoUu1LjQs09Du0JRyKU0Eyq31qdmHCj4V+M8f/yHFpPBkM/dYckOp9DQRKLdWwLMAIxuNBGBA3QH4+/rbHJFSrqdrDSm31/P2npQqVIpWFVvZHYpSttBEoNyep4cnHSp3sDsMpWyjTUNKKeXmNBEopZSb00SglFJuThOBUkq5OU0ESinl5jQRKKWUm8sXw0eTkpIIDw8nISHB7lBcplChQlSqVAlvb10hUymVPfkiEYSHh1O0aFGqVavmFouFGWM4c+YM4eHhVK9e3e5wlFJ5XL5oGkpISKB06dJukQQARITSpUu7VQ1IKeU8+SIRAG6TBNK42+dVSjlPvkkESimVXyUkpfD89zvYdOSMU8p3aiIQkSAR2S8ih0Tkxevs01dE9ojIbhH5xpnx2MHX19fuEJRSeVxUTCLzg8M5fjbeKeU7rbNYRDyBqUAnIBzYIiJLjTF70u1TE3gJaGOMOSciZZ0Vj1JK5VWRsVZ/YNlihZxSvjNHDTUHDhljjgCIyDygJ7An3T7DganGmHMAxpio7B70jWW72XMyJrvFXKVexWK81v2Om+734YcfMmvWLACGDRvGU089dWXbqVOn6NevHzExMSQnJzN9+nTatm2bo3EqpfKnqJhEAMoWLeiU8p2ZCPyB4+mehwMtrtmnFoCIbAA8gdeNMSuvLUhERgAjAKpUqeKUYLMrJCSEL774gj///BNjDC1atKB9+/ZXtn/zzTd07tyZV155hZSUFOLjnVPFU0rlP1GOGkG5PFgjyGhYi8ng+DWBDkAlYJ2I1DfGnL/qTcZ8CnwKEBAQcG0ZV8nMlbszrF+/nt69e+Pj4wPA/fffz7p1665sv/POOxkyZAhJSUn06tWLxo0b2xKnUirviYxJxNtTKFnEORNIndlZHA5UTve8EnAyg32WGGOSjDFhwH6sxJDnGHPD/ES7du1Yu3Yt/v7+DBw4kDlz5rgoMqVUXhcVm0AZ34JOGzbuzESwBagpItVFpADwELD0mn0WA3cBiIgfVlPRESfG5DTt2rVj8eLFxMfHExcXx6JFi67qAzh27Bhly5Zl+PDhDB06lK1bt9oYrVIqL4mOTXRaRzE4sWnIGJMsIqOBn7Da/2cZY3aLyDgg2Biz1LHtXhHZA6QAzxljnDNQ1smaNm3K4MGDad68OWB1Fjdp0uTK9jVr1jB+/Hi8vb3x9fXVGoFSKtMiYxKoVtrHaeXLzZo0cpuAgAATHBx81Wt79+6lbt26NkVkH3f93Eq5m8bjVtGtYQXe6tUgy2WISIgxJiCjbTqzWCmlcrHE5BTOxydRrqjzmoY0ESilVC52ZQ5BMefMIQBNBEoplatFxaZNJtMagVJKuaXoK8tLaI1AKaXcUmSM1giUUsqtRcUm4OkhlPYp4LRjaCJwkq5du3L+/Pl/vP76668zYcIEGyJSSuVFUTGJlPEtiIeH825GlS/uWZzbGGNYvnw5Hh6aZ5VS2RMZm+jU/gHIj4lgxYsQsTNnyyzfALq8d8Ndjh49SpcuXbjrrrvYuHEj27dvJzo6Gj8/P95++23mzJlD5cqVKVOmDM2aNQNgy5YtDB06FB8fHwIDA1mxYgW7du0iJSWFF198kTVr1pCYmMgTTzzBY489lrOfSSmVJ0TFJFCpZGGnHkMvWXPQ/v37GTRoENu2baNq1aqAtTz1vHnz2LZtGwsXLmTLli1X9n/00UeZMWMGGzduxNPT88rrn3/+OcWLF2fLli1s2bKFmTNnEhYW5vLPo5Syn7PXGYL8WCO4yZW7M1WtWpWWLVte9dq6devo3bs3RYoUAaBHjx4AnD9/ntjYWFq3bg1A//79Wb58OQCrVq0iNDSU77//HoALFy5w8OBBqlev7qqPopTKBS4np3Im7rLTbkiTJv8lAhul3YvgWhktHXujNZ6MMUyePJnOnTvnWGxKqbzn9EXnDx0FbRpyunbt2rFo0SIuXbpEbGwsy5YtA6BkyZIULVqUTZs2ATBv3rwr7+ncuTPTp08nKSkJgAMHDhAXF+f64JVStkqbVVxOO4vztqZNm9KvXz8aN25M1apVr7pHweeff87w4cPx8fGhQ4cOFC9eHLCWsD569ChNmzbFGEOZMmVYvHixXR9BKWWTyBjHrGIn1wh0GWobXbx4EV9fXwDee+89Tp06xaRJkzL9/rz6uZVSmfPVpmP83+Jd/Plyx2zfr/hGy1BrjcBGP/zwA++++y7JyclUrVqV2bNn2x2SUioXiY5JwENw6qxi0ERgq379+tGvXz+7w1BK5VKRMYmU9i2Il6dzu3O1s1gppXKpqNgEpw8dBU0ESimVa0XFJma7byAzNBEopVQuFRmTqDUCpZRyV8kpqZyJ00SQp6QNA1VKqZxwJu4yxuD0dYZAE4FSSuVKf08mc36NIN8NH31/8/vsO7svR8usU6oOLzR/IVP7Xrx4kZ49e3Lu3DmSkpJ466236NmzJ3FxcfTt25fw8HBSUlL4v//7P/r168eLL77I0qVL8fLy4t5772XChAkcO3aMIUOGEB0dTZkyZfjiiy+oUqVKjn4mpVTuFpV2i0oX1AjyXSKwW6FChVi0aBHFihXj9OnTtGzZkh49erBy5UoqVqzIDz/8AFgrip49e5ZFixaxb98+ROTKHc1Gjx7NoEGDeOSRR5g1axZjx47VJSaUcjOuWmcI8mEiyOyVu7MYY3j55ZdZu3YtHh4enDhxgsjISBo0aMCzzz7LCy+8QLdu3Wjbti3JyckUKlSIYcOGcd9999GtWzcANm7cyMKFCwEYOHAgzz//vJ0fSSllg8iYBETAz1c7i/OcuXPnEh0dTUhICNu3b6dcuXIkJCRQq1YtQkJCaNCgAS+99BLjxo3Dy8uLzZs306dPHxYvXkxQUFCGZWa0jLVSKn+Lik2kVJECeDt5VjHkwxqB3S5cuEDZsmXx9vZm9erVHDt2DICTJ09SqlQpBgwYgK+vL7Nnz+bixYvEx8fTtWtXWrZsSY0aNQBo3bo18+bNY+DAgcydO5fAwEA7P5JSygbRsQku6R8ATQQ57uGHH6Z79+4EBATQuHFj6tSpA8DOnTt57rnn8PDwwNvbm+nTpxMbG0vPnj1JSEjAGMPEiRMB+PjjjxkyZAjjx4+/0lmslHIvrppMBpoIcszFixcB8PPzY+PGjf/YXq1atQzvOLZ58+YM9/3tt99yPkilVJ4RFZtAnfJFXXIs7SNQSqlcJiXVcPriZZesMwSaCJRSKtc5E5dISqqhrAuGjkI+SgR57U5r2eVun1cpd3JlMpmL+gjyRSIoVKgQZ86ccZsvR2MMZ86coVAh11QblVKuFR3rulnFkE86iytVqkR4eDjR0dF2h+IyhQoVolKlSnaHoZRyAleuMwT5JBF4e3tTvXp1u8NQSqkckba8RJn80DQkIkEisl9EDonIixlsHywi0SKy3fEzzJnxKKVUXhAVm0DJIt4U9PJ0yfGcViMQEU9gKtAJCAe2iMhSY8yea3b91hgz2llxKKVUXmNNJnNdH6AzawTNgUPGmCPGmMvAPKCnE4+nlFL5QlRsosuGjoJz+wj8gePpnocDLTLYr4+ItAMOAE8bY45fu4OIjABGOJ5eFJH9WYzJDzidxffmR3o+rqbn4296Lq5my/n4Omcby6teb4MzE0FGS2ZeO75zGfA/Y0yiiIwEvgTu/sebjPkU+DTbAYkEG2MCsltOfqHn42p6Pv6m5+Jq+f18OLNpKByonO55JeBk+h2MMWeMMYmOpzOBZk6MRymlVAacmQi2ADVFpLqIFAAeApam30FEKqR72gPY68R4lFJKZcBpTUPGmGQRGQ38BHgCs4wxu0VkHBBsjFkKjBWRHkAycBYY7Kx4HLLdvJTP6Pm4mp6Pv+m5uFq+Ph/iLssyKKWUyli+WGtIKaVU1mkiUEopN+c2ieBmy124CxGpLCKrRWSviOwWkSftjik3EBFPEdkmIsvtjsVuIlJCRL4XkX2O35NWdsdkFxF52vF3sktE/ici+XLJX7dIBOmWu+gC1AP+JSL17I3KNsnAM8aYukBL4Ak3PhfpPYmOWkszCVhpjKkDNMJNz4uI+ANjgQBjTH2sQS8P2RuVc7hFIkCXu7jCGHPKGLPV8TgW64/c396o7CUilYD7gM/sjsVuIlIMaAd8DmCMuWyMOW9vVLbyAgqLiBdQhGvmQuUX7pIIMlruwq2//ABEpBrQBPjT3khs9xHwPJBqdyC5wG1ANPCFo6nsMxHxsTsoOxhjTgATgL+AU8AFY8wqe6NyDndJBJlZ7sKtiIgvsAB4yhgTY3c8dhGRbkCUMSbE7lhyCS+gKTDdGNMEiAPcsk9NREpitRxUByoCPiIywN6onMNdEsFNl7twJyLijZUE5hpjFtodj83aAD1E5ChWk+HdIvK1vSHZKhwIN8ak1RK/x0oM7ugeIMwYE22MSQIWAq1tjskp3CUR3HS5C3chIoLV/rvXGPOh3fHYzRjzkjGmkjGmGtbvxW/GmHx51ZcZxpgI4LiI1Ha81BG49h4i7uIvoKWIFHH83XQkn3ac54tbVd7M9Za7sDksu7QBBgI7RWS747WXjTE/2hiTyl3GAHMdF01HgEdtjscWxpg/ReR7YCvWaLtt5NOlJnSJCaWUcnPu0jSklFLqOjQRKKWUm9NEoJRSbk4TgVJKuTlNBEop5eY0Eah8S0TWiIjTbzguImMdq3TOveb1ABH52PG4g4jk2GQkEakmIv0zOpZSt8ot5hEodatExMsYk5zJ3UcBXYwxYelfNMYEA8GOpx2Ai8AfORRDNaA/8E0Gx1LqlmiNQNnKcWW7V0RmOtZ9XyUihR3brlzRi4ifYxkIRGSwiCwWkWUiEiYio0Xk345F0jaJSKl0hxggIn841pNv7ni/j4jMEpEtjvf0TFfudyKyDPjH4mKOY+xy/DzleG0G1kJtS0Xk6Wv27yAiyx2L+40EnhaR7SLSVkTKiMgCRwxbRKSN4z2vi8inIrIKmOM4P+tEZKvjJ61W8R7Q1lHe02nHcpRRynF+Qh3no2G6smc5zusRERmb7nz8ICI7HJ+tX/b+V1WeY4zRH/2x7QfryjYZaOx4Ph8Y4Hi8BmsteAA/4Kjj8WDgEFAUKANcAEY6tk3EWkgv7f0zHY/bAbscj99Jd4wSwAHAx1FuOFAqgzibATsd+/kCu4Emjm1HAb8M3tMBWO54/DrwbLpt3wCBjsdVsJb8SNsvBCjseF4EKOR4XBMIvrbsDI41GXjN8fhuYHu6sv8ACjrO5xnAG+iTdp4c+xW3+/dCf1z7o01DKjcIM8akLXcRgpUcbma1se6nECsiF4Bljtd3Ag3T7fc/AGPMWhEpJiIlgHuxFpp71rFPIawvY4CfjTFnMzheILDIGBMHICILgbZYyw5kxT1APWsJGwCKiUhRx+OlxphLjsfewBQRaQykALUyUXYg1pc7xpjfRKS0iBR3bPvBGJMIJIpIFFAO65xNEJH3sZLJuix+JpVHaSJQuUFiuscpQGHH42T+br689haB6d+Tmu55Klf/Xl+7horBWpa8jzFmf/oNItICa9nljGS0lHl2eACt0n3hp8XANTE8DURi3SnMA0jIRNk3Wnb92nPtZYw5ICLNgK7AuyKyyhgzLlOfQuUL2kegcrOjWE0yAA9ksYx+ACISiHVjkQtYiw+OcawoiYg0yUQ5a4FejpUofYDewK1cOcdiNWWlWQWMTnviuOLPSHHglDEmFWuxQM/rlHdtrA87yu0AnDY3uOeEiFQE4o0xX2PdiMVdl512W5oIVG42AXhcRP7AatPOinOO988AhjpeexOrySVURHY5nt+QsW7vORvYjHVHt8+MMbfSLLQM6J3WWYzjXriODt09WJ3JGZkGPCIim7CahdJqC6FAsqOD9+lr3vN6WtlYncqP3CS2BsBmx2q0rwBv3cLnUvmArj6qlFJuTmsESinl5jQRKKWUm9NEoJRSbk4TgVJKuTlNBEop5eY0ESillJvTRKCUUm7u/wHTSUyv3PxkmQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "trained_models = model_experiment(scaled_train, y_train, num_iter=10, alpha = 100,\n",
    "                                   models = ['ols', 'ridge', 'lasso'], \n",
    "                                   complexity= 'polynomial', degree = 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Your Turn__\n",
    "\n",
    "- Try different values for alpha --> report your observations\n",
    "\n",
    "- Change complexity = 'polynomial' and observe the change in the variance of the models. \n",
    "\n",
    "- Report your observations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0.   ,  -0.   ,   3.264, 274.34 ,   0.   ,  -0.   ,   0.   ,\n",
       "         0.   ,   0.   ,  -0.   ,   0.   ,  -0.   ,  -0.   ,   0.   ,\n",
       "         0.   ,   0.   ,  -0.   ,   0.   ,   0.   ,   0.   ,  -0.   ,\n",
       "        -0.   ,   0.   ,   0.   ,   0.   ,   0.   ,  -0.   ,   0.   ,\n",
       "         0.   ,   0.   ,  -0.   ,  -0.   ,   0.   ,   0.   ,   0.   ,\n",
       "        -0.   ,   0.   ,   0.   ,   0.   ,  -0.   ,  -0.   ,   0.   ,\n",
       "         0.   ,  -0.   ,  -0.   ,  -0.   ,   0.   ,  -0.   ,  -0.   ,\n",
       "         0.   ,  -0.   ,  -0.   ,   0.   ,  -0.   ,   0.   ,  -0.   ,\n",
       "        -0.   ,  -0.   ,   0.   ,  -0.   ,  -0.   ,   0.   ,   0.   ,\n",
       "         0.   ,  -0.   ,   0.   ,   0.   ,  -0.   ,   0.   ,   0.   ,\n",
       "         0.   ,   0.   ,  -0.   ,   0.   ,  -0.   ,   0.   ,  -0.   ,\n",
       "         0.   ,  -0.   ,   0.   ,   0.   ,   0.   ,  -0.   ,   0.   ,\n",
       "         0.   ,   0.   ,  -0.   ,   0.   ,   0.   ,   0.   ,   0.   ,\n",
       "         0.   ,  -0.   ,   0.   ,   0.   ,   0.   ,  -0.   ,   0.   ,\n",
       "         0.   ,   0.   ,   0.   ,  -0.   ,   0.   ,   0.   ,   0.   ,\n",
       "        -0.   ,   0.   ,   0.   ,   0.   ,   0.   ,  -0.   ,  -0.   ,\n",
       "         0.   ,  -0.   ,  -0.   ,   0.   ,  -0.   ,   0.   ,   0.   ,\n",
       "        -0.   ,   0.   ,   0.   ,  -0.   ,  -0.   ,  -0.   ,  -0.   ,\n",
       "        -0.   ,   0.   ,   0.   ,  -0.   ,  -0.   ,  -0.   ,  -0.   ,\n",
       "         0.   ,   0.   ,   0.   ,   0.   ,  -0.   ,  -0.   ,  -0.   ,\n",
       "        -0.   ,  -0.   ,   0.   ,  -0.   ,   0.   ,   0.   ,   0.   ,\n",
       "        -0.   ,   0.   ,   0.   ,   0.   ,  -0.   ,   0.   ,   0.   ,\n",
       "         0.   ,   0.   ,  -0.   ,   0.   ,   0.   ,   0.   ,  -0.   ,\n",
       "         0.   ,   0.   ,   0.   ,   0.   ,   0.   ,  -0.   ,   0.   ,\n",
       "         0.   ,  -0.   ,   0.   ,   0.   ,  -0.   ,  -0.   ,  -0.   ,\n",
       "         0.   ,  -0.   ,  -0.   ,   0.   ,  -0.   ,   0.   ,  -0.   ,\n",
       "         0.   ,   0.   ,   0.   ,  -0.   ,  -0.   ,  -0.   ,   0.   ,\n",
       "         0.   ,  -0.   ,   0.   ,  -0.   ,   0.   ,   0.   ,  -0.   ,\n",
       "         0.   ,  -0.   ,   0.   ,   0.   ,   0.   ,  -0.   ,   0.   ,\n",
       "         0.   ,   0.   ,  -0.   ,   0.   ,   0.   ,   0.   ,   0.   ,\n",
       "         0.   ,  -0.   ,   0.   ,   0.   ,  -0.   ,  -0.   ,   0.   ,\n",
       "        -0.   ,  -0.   ,  -0.   ,   0.   ,  -0.   ,  -0.   ,   0.   ,\n",
       "        -0.   ,   0.   ,  -0.   ,   0.   ,   0.   ,   0.   ,  -0.   ,\n",
       "        -0.   ,  -0.   ,   0.   ,   0.   ,  -0.   ,   0.   ,  -0.   ,\n",
       "         0.   ,  -0.   ,  -0.   ,   0.   ,  -0.   ,   0.   ,   0.   ,\n",
       "        -0.   ,  -0.   ,  -0.   ,   0.   ,   0.   ,   0.   ,  -0.   ,\n",
       "         0.   ,  -0.   ,  -0.   ,  -0.   ,   0.   ,  -0.   ,  -0.   ,\n",
       "         0.   ,  -0.   ,  -0.   ,   0.   ,  -0.   ,  -0.   ,  -0.   ,\n",
       "        -0.   ,   0.   ,   0.   ,  -0.   ,   0.   ,  -0.   ,   0.   ,\n",
       "        -0.   ,   0.   ,  -0.   ,   0.   ,   0.   ,   0.   ,   0.   ,\n",
       "        -0.   ,  -0.   ,   0.   ,  -0.   ,  -0.   ,   0.   ,  -0.   ,\n",
       "        -0.   ,   0.   ,  -0.   ,   0.   ,   0.   ,   0.   ,  -0.   ,\n",
       "        -0.   ,   0.   ,   0.   ,   0.   ,  -0.   ,   0.   ,  -0.   ,\n",
       "        -0.   ,  -0.   ,   0.   ,   0.   ,  -0.   ,   0.   ,  -0.   ,\n",
       "         0.   ,   0.   ,   0.   ,   0.   ,   0.   ,  -0.   ,   0.   ,\n",
       "         0.   ,  -0.   ,   0.   ,  -0.   ,  -0.   ,   0.   ,   0.   ,\n",
       "        -0.   ,   0.   ,   0.   ,   0.   ,   0.   ,  -0.   ,   0.   ,\n",
       "         0.   ,   0.   ,   0.   ,   0.   ,  -0.   ,  -0.   ,  -0.   ,\n",
       "        -0.   ,   0.   ,   0.   ,   0.   ,   0.   ,   0.   ,  -0.   ,\n",
       "         0.   ,   0.   ,  -0.   ,   0.   ,  -0.   ,   0.   ,  -0.   ,\n",
       "         0.   ,   0.   ,   0.   ,   0.   ,  -0.   ,  31.651,  -0.   ,\n",
       "         0.   ,  -0.   ,   0.   ,   0.   ,  -0.   ,   0.   ,  -0.   ])"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# After run model_experiment with complexity == 'polynomial'\n",
    "\n",
    "lr_ols = trained_models['ols']\n",
    "lr_lasso = trained_models['lasso']\n",
    "lr_ridge =trained_models['ridge']\n",
    "\n",
    "# check the coefficients from Lasso\n",
    "lr_lasso.coef_\n",
    "\n",
    "# compare them with OLS/Ridge models.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0.   , -28.739,  51.753,  52.133,   8.164,  -6.361,  -1.424,\n",
       "        -1.363,  -0.337,  -0.208,  16.527,   0.674, -13.022, -11.117,\n",
       "       -12.102,  -2.273,  -0.704,   9.254,   1.588,   1.59 ,   3.44 ,\n",
       "         3.984,  -5.031,   7.346,   6.8  ,   0.902,  -4.395,   1.347,\n",
       "        -9.183, -10.292,  -0.422,  -8.509,   9.012,   6.256,   0.871,\n",
       "        -3.995,   1.767,  -9.807,  -8.971,  -0.617,  -8.179,   9.757,\n",
       "         1.581,  -2.146,   0.595, -10.934,   2.73 ,  -4.953,  -5.902,\n",
       "         6.777,  -3.856,  -0.302,   5.336,   3.162,  -4.136,  -4.814,\n",
       "         0.042,   0.878,  -3.807,  -0.634,   0.089,   4.065,  -1.077,\n",
       "        -1.363,   1.465,  -1.156,  -0.036,  -4.077,  -0.337,   2.516,\n",
       "         2.642,   3.66 ,  -0.208,  -0.542,   0.656,  16.527,  -2.949,\n",
       "        -0.674, -12.591,  -2.494,  -2.944,   1.808,  -6.109,   3.953,\n",
       "         4.886,   6.839,  -3.68 ,   5.851,  -0.557,   1.762,   1.461,\n",
       "        -4.082,  -1.949,   2.525,   5.208,   2.951,  -0.011,   3.307,\n",
       "         2.241,   1.132,  -3.932,  -1.774,   3.086,   5.406,   3.299,\n",
       "         0.131,   3.508,   1.241,  -8.177,   5.222,  -1.633,   3.028,\n",
       "        -1.762,  -3.386,  -3.683,   6.026, -18.752,   2.535,   1.981,\n",
       "        -0.29 ,   4.93 ,   4.298,   3.91 , -18.1  ,  -1.593,  -9.023,\n",
       "        -1.377,  -1.001,   1.899, -18.35 ,  10.021,  -1.185,  -2.585,\n",
       "         1.784, -15.649,  -3.354,   1.092,   2.279, -28.74 ,  -0.081,\n",
       "        -1.381,  -5.353,   6.761, -27.602,   8.211,   8.058,  -4.645,\n",
       "         2.153,  -2.59 ,   4.822,  -0.066,   2.236,  -6.266,   5.108,\n",
       "         7.955,  -3.494,   2.217,  -2.471,   4.73 ,   0.167,   2.814,\n",
       "        -6.061,   4.396,  19.083,   3.382,   2.191,  -3.339,   1.901,\n",
       "         9.856,  -6.187,  -5.538,  22.695,  -6.575,  -7.275,   1.457,\n",
       "        -0.904,  -2.357,   1.285,  20.094,   2.937,   1.676,  -0.814,\n",
       "        -1.143,   0.311,  27.454,  -7.687,  -5.303,   0.329,  -2.243,\n",
       "        24.223,  -1.736,   1.567,  -8.633,  51.802,  -3.416,  -1.381,\n",
       "        12.565,  -1.88 ,  48.146,   7.904,  -2.35 ,   2.349,  -2.362,\n",
       "         4.664,   0.383,   3.203,  -5.694,   3.656,  19.436,   3.905,\n",
       "         1.915,  -2.19 ,   1.361,   7.493,  -4.71 ,  -5.636,  22.976,\n",
       "        -5.285,  -5.978,   1.175,  -2.217,  -3.34 ,   1.018,  19.685,\n",
       "         2.423,   2.349,  -1.158,  -2.347,   0.898,  27.433,  -8.491,\n",
       "        -3.919,  -0.157,  -2.142,  25.468,  -3.013,   1.33 ,  -8.181,\n",
       "        52.178,  -4.653,  -0.768,  12.785,  -1.637,  47.87 ,   4.237,\n",
       "         0.721,  -3.534,  -2.715,  -4.295,  -2.39 ,   9.663,   4.216,\n",
       "         8.195,   4.825,   2.645,   0.559,  10.462,  -0.346,   0.184,\n",
       "        -5.022,  -5.316,   9.194,   6.082,  -7.37 ,  -4.459,  -2.443,\n",
       "         2.832,   5.58 ,   6.482,   2.967,   8.468,  -7.495,   1.055,\n",
       "        -5.177,   8.085,  -0.206,  -3.22 ,  -2.669,   4.5  ,   4.796,\n",
       "        -3.425,   0.76 ,   1.403,  -2.805,  -3.064,  10.041,  -6.844,\n",
       "         3.815,   1.291,   0.626,   2.874,   8.511,   6.939,  -0.399,\n",
       "        -3.68 ,   4.052,  -1.835,   3.124,  -1.73 ,   7.9  ,  -3.116,\n",
       "         0.918,  -6.419,  -1.384,   9.058,  -7.147,   4.402,  -5.842,\n",
       "         0.982,  -0.046,   5.263,   0.719,   9.744,  -2.734,  -3.723,\n",
       "         4.186,  -4.741,   1.899,  -0.289,  -1.51 ,   1.641,  -0.967,\n",
       "        -2.41 ,  -1.423,  -1.92 ,   7.27 ,   3.295,  -4.372,  -0.842,\n",
       "        -1.363,   0.902,  -0.99 ,  12.009,  -2.544,  -0.265,  -0.99 ,\n",
       "        -9.467,  -0.169,  -1.379,   4.158,   3.025,  -0.524, -10.627,\n",
       "         0.445,  -0.337,   1.775,  11.512,   3.204,  -0.306,  -2.447,\n",
       "         3.24 ,   2.335,   3.046,  -1.809,  -0.208,  16.552,   0.683,\n",
       "        -0.577,  -2.363,  -0.464,  16.527,  -2.516,  14.561,   0.674])"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the coefficients from Lasso\n",
    "lr_ridge.coef_\n",
    "\n",
    "# compare them with OLS/Ridge models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Effect of Scaling Data__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([37., 19., 18.,  8.,  9.,  2.,  2.,  2.,  1.,  2.]),\n",
       " array([-1.055, -0.585, -0.114,  0.357,  0.827,  1.298,  1.769,  2.24 ,\n",
       "         2.71 ,  3.181,  3.652]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = np.random.exponential(scale = 3, size = 100)\n",
    "\n",
    "plt.hist(x)\n",
    "\n",
    "\n",
    "x_scaled = (x - x.mean())/x.std(ddof = 1)\n",
    "\n",
    "\n",
    "plt.hist(x_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Normalization__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([37., 19., 18.,  8.,  9.,  2.,  2.,  2.,  1.,  2.]),\n",
       " array([-0.073, -0.04 , -0.008,  0.025,  0.057,  0.089,  0.122,  0.154,\n",
       "         0.186,  0.219,  0.251]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.subplot(1)\n",
    "x_normalized = (x - x.mean())/np.sqrt(x.dot(x))\n",
    "plt.hist(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "#### Effect of $\\alpha$ in Lasso and Ridge\n",
    "\n",
    "<img src=\"lasso_effect_of_lambda.png\" alt=\"Lasso-Lambda\" style=\"width: 500px;\"/>\n",
    "\n",
    "<img src=\"ridge_effect_of_lambda.png\" alt=\"Lasso-Lambda\" style=\"width: 500px;\"/>\n",
    "\n",
    "<a name='questions'></a>\n",
    "\n",
    "\n",
    "#### Appendix\n",
    "<a name='appendix'></a>\n",
    "\n",
    "Here I would like to add some reading material that I found useful while working with the code.\n",
    "\n",
    "\n",
    "- [pd.get_dummies or OneHotEncoder? - Read second answer](https://stackoverflow.com/questions/36631163/pandas-get-dummies-vs-sklearns-onehotencoder-what-are-the-pros-and-cons)\n",
    "\n",
    "- [On dummy variable trap](https://www.algosome.com/articles/dummy-variable-trap-regression.html)\n",
    "\n",
    "- [sklearn.preprocessing.PolynomialFeatures documentation](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.PolynomialFeatures.html)\n",
    "\n",
    "- [A great notebook on Lasso and Ridge](https://github.com/gokererdogan/JaverianaMLCourse/blob/master/Lectures/05.pdf)\n",
    "\n",
    "- [Another good blog post on Lasso and Ridge](https://www.analyticsvidhya.com/blog/2016/01/complete-tutorial-ridge-lasso-regression-python/)\n",
    "\n",
    "- Learn.co -- Section-28 Lasso-Ridge\n",
    "\n",
    "- [Toward Datascience Article](https://towardsdatascience.com/understanding-the-bias-variance-tradeoff-165e6942b229)\n",
    "\n",
    "- [ISLR](http://faculty.marshall.usc.edu/gareth-james/ISL/) 2.2.2 The Bias-Variance Trade-off and 6.2 Shrinkage Methods\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Image Sources in order of appearance: \n",
    "- https://docs.aws.amazon.com/machine-learning/latest/dg/model-fit-underfitting-vs-overfitting.html\n",
    "\n",
    "- https://towardsdatascience.com/ensemble-methods-bagging-boosting-and-stacking-c9214a10a205\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
