{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "__Content__\n",
    "\n",
    "- [Objectives](#objectives)\n",
    "\n",
    "- [Review](#review)\n",
    "\n",
    "- [Regularization Techniques](#regularization_techniques)\n",
    "\n",
    "- [Questions](#questions)\n",
    "\n",
    "- [Appendix](#appendix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Objectives \n",
    "<a name=\"objectives\"></a>\n",
    "\n",
    "- Understand what is regularization\n",
    "\n",
    "- Understand the effect of hyper-parameter $\\alpha$ in Ridge and Lasso.\n",
    "\n",
    "- Understand the similarities and differences between Lasso-Ridge-Linear models.\n",
    "\n",
    "- Apply Lasso and Ridge with sklearn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Review\n",
    "<a name=\"review\"></a>\n",
    "\n",
    "\n",
    "\n",
    "[__Overfitting - Underfitting__](https://github.com/gokererdogan/JaverianaMLCourse/blob/master/Lectures/05.pdf)\n",
    "\n",
    "<img src=\"underfitting_overfitting.png\" alt=\"Bias-Variance\" style=\"width: 500px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "\n",
    "\n",
    "[__Bias - Variance Trade-Off__](http://scott.fortmann-roe.com/docs/BiasVariance.html)\n",
    "\n",
    "<img src=\"bias_variance_trade_off.png\" alt=\"Bias-Variance\" style=\"width: 400px;\"/>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Preliminaries - L1 and L2 Norms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Suppose we have a vector:  \n",
    "\n",
    "$$\n",
    "  \\begin{align}\n",
    "    X &= \\begin{bmatrix}\n",
    "           x_{1} \\\\\n",
    "           x_{2} \\\\\n",
    "           x_{3} \\\\\n",
    "           x_{4}\n",
    "         \\end{bmatrix}\n",
    "  \\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Then the square of the \"__L2-norm__\" of this vector is given by:\n",
    "\n",
    "$$ \\| X \\|^{2}_{2} = x_{1}^{2} + x_{2}^{2} + x_{3}^{2} +x_{4}^{2} = \\sum_{i=1}^{4} x_{i}^{2}$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31.12876483254676"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## using numpy:\n",
    "import numpy as np\n",
    "X = np.array([12, -25, 10, -10])\n",
    "\n",
    "##L2 norm of X\n",
    "np.sqrt(sum(X*X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Similarly the \"__L1-norm__\" of the X is given as:\n",
    "\n",
    "$$ \\| X \\|_{1} = \\lvert x_{1}\\rvert + \\lvert x_{2}\\rvert + \\lvert x_{3}\\rvert + \\lvert x_{4}\\rvert = \\sum_{i=1}^{4} \\lvert x_{i}\\rvert $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.449489742783178 4\n"
     ]
    }
   ],
   "source": [
    "X = np.array([2, 0, 1, -1])\n",
    "l1_norm = sum(np.abs(X))\n",
    "l1_norm\n",
    "l2_norm = np.sqrt(sum(X*X))\n",
    "\n",
    "print(l2_norm, l1_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "In two dimensions: If $$\n",
    "  \\begin{align}\n",
    "    X &= \\begin{bmatrix}\n",
    "           x_{1} \\\\\n",
    "           x_{2} \\\\\n",
    "         \\end{bmatrix}\n",
    "  \\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "$$\\text{(Lasso) ---->} \\| X \\|_{1} = \\lvert x_{1}\\rvert + \\lvert x_{2}\\rvert = \\sum_{i=1}^{2} \\lvert x_{i}\\rvert $$\n",
    "\n",
    "$$\\text{(Ridge) ---->} \\| X \\|_{2}^{2} = \\lvert x_{1}\\rvert^{2} + \\lvert x_{2}\\rvert^{2} = \\sum_{i=1}^{2} \\lvert x_{i}\\rvert^{2} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"norms.png\" alt=\"Lasso-Lambda\" style=\"width: 400px;\" class = \"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Examples: Note that if we have two vectors $ \\begin{align}\n",
    "    X &= \\begin{bmatrix}\n",
    "           x_{1} \\\\\n",
    "           x_{2} \\\\\n",
    "           x_{3} \\\\\n",
    "           x_{4}\n",
    "         \\end{bmatrix}\n",
    "  \\end{align}$   and $ \\begin{align}\n",
    "    Y &= \\begin{bmatrix}\n",
    "           y_{1} \\\\\n",
    "           y_{2} \\\\\n",
    "           y_{3} \\\\\n",
    "           y_{4}\n",
    "         \\end{bmatrix}\n",
    "  \\end{align}$ we can subtract them and get a new vector: $ \\begin{align}\n",
    "    X - Y &= \\begin{bmatrix}\n",
    "           x_{1} - y_{1} \\\\\n",
    "           x_{2} - y_{2}\\\\\n",
    "           x_{3} - y_{3}\\\\\n",
    "           x_{4} - y_{4}\n",
    "         \\end{bmatrix}\n",
    "  \\end{align}$. Then now we can calculate the __L1-norm__ of the new vector $X-Y$ as:\n",
    "  \n",
    "  $$ \\| X-Y \\|_{1} = \\lvert x_{1} - y_{1} \\rvert + \\lvert x_{2} - y_{2} \\rvert + \\lvert x_{3} - y_{3} \\rvert + \\lvert x_{4} - y_{4} \\rvert = \\sum\\limits_{i=1}^{4} \\lvert x_{i} - y_{i} \\rvert$$\n",
    "  \n",
    "  Similarly the __L2-norm__ of this vector is given by:\n",
    "  \n",
    "  $$ \\| X-Y \\|_{2}^{2} =  (x_{1} - y_{1})^{2} + (x_{2} - y_{2} )^{2} + ( x_{3} - y_{3} )^{2} + ( x_{4} - y_{4} )^{2} =\\sum\\limits_{i=1}^{4} ( x_{i} - y_{i} )^{2} $$\n",
    "  \n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Linear Regression Recap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "#### Linear Model\n",
    "\n",
    "$$ Y = w_{0} + w_{1}X_1 + w_{2}X_{2} + \\cdots + w_{p}X_{p} + \\varepsilon $$\n",
    "\n",
    " - We train model to understand the paramaters $w_{i}$ (Coefficients) \n",
    "\n",
    " - $X_{i}$ 's are columns of the datasets (Features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Once the coefficients are estimated (learned): We can make predictions for an observation (row) in our dataset:\n",
    "\n",
    " $$ \\hat{y}_{i} =  \\hat{w}_{0} + \\hat{w}_{1}X_{i1} + \\hat{w}_{2}X_{i2} + \\cdots + \\hat{w}_{p}X_{ip}$$\n",
    " \n",
    " - $\\hat{w}_{i}$'s are estimated coefficients\n",
    " - $X_{i1}, X_{i2}, \\cdots, X_{ip}$ - i'th row in the dataset (with p-columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    " \n",
    " Therefore for each observations (rows) errors are given by:\n",
    " \n",
    " $$ e_{i} = y_{i} - \\hat{y}_{i} $$\n",
    " \n",
    " As a result, the Residual Sum of Squares can be expressed as:\n",
    " \n",
    " $$ RSS(\\hat{w}_{0}, \\cdots, \\hat{w}_{p}) = \\sum\\limits_{i=0}^{N} e_{i}^{2}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "\n",
    "Usually the cost functions are denoted with the capital letter $J$\n",
    " \n",
    " \n",
    " $$ J(\\hat{w}_{0}, \\cdots, \\hat{w}_{p}) = \\sum\\limits_{i=0}^{N} (y_{i} - \\hat{w}_{0} - \\hat{w}_{1}X_{i1} - \\hat{w}_{2}X_{i2} - \\cdots - \\hat{w}_{p}X_{i_p})^{2} $$\n",
    " \n",
    " And this equation can be written in short hand as:\n",
    " \n",
    " $$ J(\\boldsymbol{w}) = \\| \\boldsymbol{Y} - X \\hat{w} \\|_{2}^{2} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Ridge regularization\n",
    "\n",
    "Instead of minimizing $J(w)$ (least squares method), we will minimize:\n",
    "\n",
    "$$ J_{\\alpha}(\\boldsymbol{w}) = J(\\boldsymbol{w}) + \\alpha\\sum_{i=1}^{p} w_{i}^{2} $$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### Lasso regularization\n",
    "\n",
    "Instead of minimizing $J(\\boldsymbol{w})$, we will minimize:\n",
    "\n",
    "$$ J_{\\alpha}(\\boldsymbol{w}) = J(\\boldsymbol{w}) + \\alpha\\sum_{i=1}^{p}| w_{i} | $$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Regularization Techniques\n",
    "\n",
    "<a name=\"regularization_techniques\"></a>\n",
    "\n",
    "\n",
    "- Why?\n",
    "\n",
    "    - Reduces complexity\n",
    "    \n",
    "    - Reduce the chance of overfitting.\n",
    "    \n",
    "    - Reduces model's variance at the expense of introducing small bias\n",
    "    \n",
    "    - Increases model's interprettability.\n",
    "    \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## An Example with Sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "init_cell": true
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-9f3299c5ab59>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m## import libraries\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'matplotlib'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'inline'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplotting\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mscatter_matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'matplotlib'"
     ]
    }
   ],
   "source": [
    "## import libraries\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from pandas.plotting import scatter_matrix\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "# load data \n",
    "import pandas as pd\n",
    "df = pd.read_csv('../data/Credit.csv', index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "# let's see the head of the dataset\n",
    "print(df.shape)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A Brief Investigation of the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "## checking for missing values\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "## let's see the number of categories in ethnicity\n",
    "df.Ethnicity.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "df.Gender.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "df.Student.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "df.Married.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df.drop(columns = \"Balance\"),\n",
    "                                                df.Balance, \n",
    "                                                stratify = df.Married,\n",
    "                                                random_state =42, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One Hot Encoding the Categorical Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "## instantiate ohe\n",
    "## note that in this case we know the categories very well.\n",
    "## import\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "## instantiate\n",
    "ohe = OneHotEncoder(categories= [[\"Caucasian\", \"Asian\", \"African American\"], [\"Female\", \" Male\"], [\"No\", \"Yes\"], [\"Yes\", \"No\"]],\n",
    "                    drop = [\"Caucasian\", \"Female\", \"No\", \"No\"], sparse = False,)\n",
    "\n",
    "## fit model (learn categories in train and plan how to convert them one hot encoded columns)\n",
    "ohe.fit(X_train[['Ethnicity', \"Gender\", \"Student\", \"Married\"]])\n",
    "## transform X_train data. Result is a numpy array.\n",
    "categorical_train = ohe.transform(X_train[['Ethnicity', \"Gender\", \"Student\", \"Married\"]])\n",
    "## concact the categorical variables with the rest of the data\n",
    "train = np.hstack((X_train.select_dtypes(exclude = \"object\" ), categorical_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(320, 11)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "## note that we should make the similar transformation to the test data too.\n",
    "## Remark: Never fit a transformer to your test data. Only transform!!\n",
    "categorical_test = ohe.transform(X_test[['Ethnicity', \"Gender\", \"Student\", \"Married\"]])\n",
    "test = np.hstack((X_test.select_dtypes(exclude = \"object\"), categorical_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80, 11)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['x0_Asian', 'x0_African American', 'x1_ Male', 'x2_Yes', 'x3_Yes'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ohe.get_feature_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting a Linear Regression (Baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "## import \n",
    "from sklearn.linear_model import LinearRegression\n",
    "## instantiate\n",
    "lr = LinearRegression()\n",
    "## fit \n",
    "lr.fit(train, y_train)\n",
    "## predict\n",
    "y_train_pred = lr.predict(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -7.691,   0.181,   1.227,  15.466,  -0.671,  -1.419,   7.498,\n",
       "        -2.283,   8.193, 433.656,  -5.428])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.set_printoptions(suppress=True, precision=3)\n",
    "lr.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9532149163845625"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## R_squared score\n",
    "lr.score(train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "## import\n",
    "from sklearn.linear_model import Ridge\n",
    "## instantiate\n",
    "ridge = Ridge(alpha = 20, normalize = True) ## note that we should normalize/standardize data if you are using regularization\n",
    "## fit\n",
    "ridge.fit(train, y_train)\n",
    "## predict\n",
    "ridge_train_pred = ridge.predict(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.252,  0.008,  0.114,  1.475, -0.021,  0.069,  0.767,  3.418,\n",
       "       -2.207, 21.428,  0.252])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## coefficients\n",
    "ridge.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1512520485978246"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## score\n",
    "ridge.score(train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -0.318,   0.024,   1.904,   0.   ,  -0.   ,   0.   ,   0.   ,\n",
       "         0.   ,  -0.   , 242.081,  -0.   ])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## import\n",
    "from sklearn.linear_model import Lasso\n",
    "## instantiate\n",
    "lasso = Lasso(alpha= 3, normalize= True)\n",
    "## fit\n",
    "lasso.fit(train, y_train)\n",
    "## predict\n",
    "lasso_train_pred = lasso.predict(train)\n",
    "## coefficients\n",
    "lasso.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8014911464840078"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## score\n",
    "\n",
    "lasso.score(train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some Important Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions\n",
    "\n",
    "\n",
    "\n",
    "__Q.__ Should I do normalization for Lasso or Ridge?\n",
    "\n",
    "A. Yes? Why?\n",
    "\n",
    "__Q.__ When we know that Ridge and Lasso is better than vanilla linear regression?\n",
    "\n",
    "A. High variation in your model --> Colinearity and too many variables.\n",
    "\n",
    "__Q.__ How do we know whether we should choose Lasso or Ridge?\n",
    "\n",
    "A. Most of the time they perform very similar but Lasso has the feature selection property, ridge doesn't have this.\n",
    "\n",
    "__Q:__ How do we choose $\\lambda$?\n",
    "\n",
    "A. [sklearn gridsearch](https://scikit-learn.org/stable/modules/grid_search.html#grid-search) for small models or random grid search for bigger models.\n",
    "\n",
    "Or check-out: \n",
    "\n",
    "[Sklearn - LassoLarsIC](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LassoLarsIC.html)\n",
    "\n",
    "[Sklearn - LassoCV](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LassoCV.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Miscellaneous"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "## import\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "## instantiate\n",
    "scaler = StandardScaler()\n",
    "## fit\n",
    "scaler.fit(train)\n",
    "## transform\n",
    "scaled_train = scaler.transform(train) \n",
    "## Apply to test: !! Don't fit only transform\n",
    "scaled_test = scaler.transform(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observing the effect of Regularization in Polynomial Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After adding higher order terms:  (320, 4368) (80, 4368)\n"
     ]
    }
   ],
   "source": [
    "## import\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "## instantiate -- with desired degree. \n",
    "poly = PolynomialFeatures(degree=5)\n",
    "## fit\n",
    "poly.fit(scaled_train)\n",
    "## transform\n",
    "Xp_train = poly.transform(scaled_train)\n",
    "## apply to test: !! Don't fit only transform\n",
    "Xp_test = poly.transform(scaled_test)\n",
    "print('After adding higher order terms: ', Xp_train.shape, Xp_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Selection with Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 793460.484187546, tolerance: 5257.7543359375\n",
      "  positive)\n",
      "/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1722184.8873493765, tolerance: 5440.306824609375\n",
      "  positive)\n",
      "/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1774828.4260413772, tolerance: 5469.784321484375\n",
      "  positive)\n",
      "/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1324537.1780131762, tolerance: 5191.286458984375\n",
      "  positive)\n",
      "/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1228092.101837951, tolerance: 5195.538730859375\n",
      "  positive)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "## import\n",
    "from sklearn.model_selection import cross_validate\n",
    "## note that cross-validate is a function so we don't need to instantiate it\n",
    "\n",
    "\n",
    "## chose a model for validate\n",
    "lasso = Lasso(alpha = 10)\n",
    "\n",
    "cv = cross_validate(estimator=lasso, X=Xp_train, y=y_train, cv = 5, return_estimator= True, return_train_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type of cv object is <class 'dict'>\n",
      "Keys of cv object is dict_keys(['fit_time', 'score_time', 'estimator', 'test_score', 'train_score'])\n"
     ]
    }
   ],
   "source": [
    "## cv is an dict object\n",
    "print(\"Type of cv object is\", type(cv))\n",
    "print(\"Keys of cv object is\", cv.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.973 0.976 0.974 0.974 0.972]\n",
      "[0.719 0.689 0.874 0.961 0.946]\n"
     ]
    }
   ],
   "source": [
    "print(cv['train_score'])\n",
    "\n",
    "## note that even though the name is test_score this is in fact validation score\n",
    "print(cv['test_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_experiment(X, y, num_iter = 5, \n",
    "                     models = ['ols', 'ridge', 'lasso'], alpha= 10, \n",
    "                     complexity = 'simple', degree = 3):\n",
    "    \"\"\"\n",
    "    parameters:\n",
    "    _________________________\n",
    "    num_iter: int, number of times fit the models to test data each time with different splitting. \n",
    "    note that for each iteration we split the data random train and test parts.\n",
    "    models: list, list of models that we want to use. Options are 'ols' for simple linear regression\n",
    "    'ridge' for ridge regression and 'lasso' for lasso regression.\n",
    "    alpha: float, alpha parameter for ridge and lasso algorithms. Recall that higher values of alpha \n",
    "    leads to more regularization.\n",
    "    complexity: str, either 'simple' or 'polynomial'. We either use the original dataset or \n",
    "    a dataset with polynomial powers generated. \n",
    "    degree: int, if complexity is polynomial then degree is the degrees of polynomials to be generated.\n",
    "    return: dict, it returns a dictionary with trained models as values and the 'complexity' parameters as keys.\n",
    "    \"\"\"\n",
    "    \n",
    "    x_axis = np.arange(num_iter)\n",
    "    y_ols_test = []\n",
    "    y_lasso_test = []\n",
    "    y_ridge_test = []\n",
    "    sample_models = {}\n",
    "    for i in range(num_iter):\n",
    "        \n",
    "        if complexity == 'simple':\n",
    "            ## split train_test \n",
    "            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)\n",
    "        elif complexity == 'polynomial':\n",
    "            ## Create higher order terms\n",
    "            poly = PolynomialFeatures(degree=degree)\n",
    "            Xp = poly.fit_transform(X)\n",
    "            ## test-train split\n",
    "            X_train, X_test, y_train, y_test = train_test_split(Xp, y, test_size = 0.2)\n",
    "\n",
    "\n",
    "        ## Standard scale mean = 0, variance = 1\n",
    "        sd = StandardScaler()\n",
    "\n",
    "        sd.fit(X_train)\n",
    "\n",
    "        X_train = sd.transform(X_train)\n",
    "\n",
    "        X_test = sd.transform(X_test)\n",
    "\n",
    "        ## Be careful about the leakage\n",
    "\n",
    "        ## Vanilla model\n",
    "        if 'ols' in models:\n",
    "            lr = LinearRegression()\n",
    "\n",
    "            lr.fit(X_train, y_train)\n",
    "            \n",
    "            sample_models['ols'] = lr\n",
    "\n",
    "            test_score = lr.score(X_test, y_test)\n",
    "            train_score = lr.score(X_train, y_train)\n",
    "\n",
    "            y_ols_test.append(test_score)\n",
    "\n",
    "    #       print('test score OLS is %.2f and train score is %.2f'%(test_score, train_score))\n",
    "\n",
    "        if 'ridge' in models:\n",
    "            ## Ridge in the simple setting\n",
    "            ridge = Ridge(alpha = alpha, max_iter= 10000)\n",
    "            ridge.fit(X_train, y_train)\n",
    "            sample_models['ridge'] = ridge\n",
    "            y_ridge_test.append(ridge.score(X_test, y_test))\n",
    "    #         print('test score Ridge is %.2f and train score is %.2f'%(ridge.score(X_test, y_test),\n",
    "    #                                                             ridge.score(X_train, y_train)))\n",
    "\n",
    "        if 'lasso' in models:\n",
    "            ## Lasso in the simple setting\n",
    "            lasso = Lasso(alpha = alpha, max_iter= 10000)\n",
    "\n",
    "            lasso.fit(X_train, y_train)\n",
    "            \n",
    "            sample_models['lasso'] = lasso\n",
    "            \n",
    "            y_lasso_test.append(lasso.score(X_test, y_test))\n",
    "    #       print('test score Lasso is %.2f and train score is %.2f'%(lasso.score(X_test, y_test),\n",
    "    #                                                             lasso.score(X_train, y_train)))\n",
    "\n",
    "        i+=1\n",
    "    if 'ols' in models:\n",
    "        plt.plot(y_ols_test, label = 'ols')\n",
    "    if 'ridge' in models:\n",
    "        plt.plot(y_ridge_test, label = 'ridge')\n",
    "    if 'lasso' in models:\n",
    "        plt.plot(y_lasso_test, label = 'lasso')\n",
    "    plt.ylabel('R2 test score')\n",
    "    plt.xlabel('number of iterations')\n",
    "    plt.ylim((0.50, 0.99))\n",
    "    \n",
    "    plt.legend()\n",
    "    return sample_models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "trained_models = model_experiment(scaled_train, y_train, num_iter=10, alpha = 100,\n",
    "                                   models = ['ols', 'ridge', 'lasso'], \n",
    "                                   complexity= 'polynomial', degree = 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Your Turn__\n",
    "\n",
    "- Try different values for alpha --> report your observations\n",
    "\n",
    "- Change complexity = 'polynomial' and observe the change in the variance of the models. \n",
    "\n",
    "- Report your observations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0.   ,  -0.   ,   3.264, 274.34 ,   0.   ,  -0.   ,   0.   ,\n",
       "         0.   ,   0.   ,  -0.   ,   0.   ,  -0.   ,  -0.   ,   0.   ,\n",
       "         0.   ,   0.   ,  -0.   ,   0.   ,   0.   ,   0.   ,  -0.   ,\n",
       "        -0.   ,   0.   ,   0.   ,   0.   ,   0.   ,  -0.   ,   0.   ,\n",
       "         0.   ,   0.   ,  -0.   ,  -0.   ,   0.   ,   0.   ,   0.   ,\n",
       "        -0.   ,   0.   ,   0.   ,   0.   ,  -0.   ,  -0.   ,   0.   ,\n",
       "         0.   ,  -0.   ,  -0.   ,  -0.   ,   0.   ,  -0.   ,  -0.   ,\n",
       "         0.   ,  -0.   ,  -0.   ,   0.   ,  -0.   ,   0.   ,  -0.   ,\n",
       "        -0.   ,  -0.   ,   0.   ,  -0.   ,  -0.   ,   0.   ,   0.   ,\n",
       "         0.   ,  -0.   ,   0.   ,   0.   ,  -0.   ,   0.   ,   0.   ,\n",
       "         0.   ,   0.   ,  -0.   ,   0.   ,  -0.   ,   0.   ,  -0.   ,\n",
       "         0.   ,  -0.   ,   0.   ,   0.   ,   0.   ,  -0.   ,   0.   ,\n",
       "         0.   ,   0.   ,  -0.   ,   0.   ,   0.   ,   0.   ,   0.   ,\n",
       "         0.   ,  -0.   ,   0.   ,   0.   ,   0.   ,  -0.   ,   0.   ,\n",
       "         0.   ,   0.   ,   0.   ,  -0.   ,   0.   ,   0.   ,   0.   ,\n",
       "        -0.   ,   0.   ,   0.   ,   0.   ,   0.   ,  -0.   ,  -0.   ,\n",
       "         0.   ,  -0.   ,  -0.   ,   0.   ,  -0.   ,   0.   ,   0.   ,\n",
       "        -0.   ,   0.   ,   0.   ,  -0.   ,  -0.   ,  -0.   ,  -0.   ,\n",
       "        -0.   ,   0.   ,   0.   ,  -0.   ,  -0.   ,  -0.   ,  -0.   ,\n",
       "         0.   ,   0.   ,   0.   ,   0.   ,  -0.   ,  -0.   ,  -0.   ,\n",
       "        -0.   ,  -0.   ,   0.   ,  -0.   ,   0.   ,   0.   ,   0.   ,\n",
       "        -0.   ,   0.   ,   0.   ,   0.   ,  -0.   ,   0.   ,   0.   ,\n",
       "         0.   ,   0.   ,  -0.   ,   0.   ,   0.   ,   0.   ,  -0.   ,\n",
       "         0.   ,   0.   ,   0.   ,   0.   ,   0.   ,  -0.   ,   0.   ,\n",
       "         0.   ,  -0.   ,   0.   ,   0.   ,  -0.   ,  -0.   ,  -0.   ,\n",
       "         0.   ,  -0.   ,  -0.   ,   0.   ,  -0.   ,   0.   ,  -0.   ,\n",
       "         0.   ,   0.   ,   0.   ,  -0.   ,  -0.   ,  -0.   ,   0.   ,\n",
       "         0.   ,  -0.   ,   0.   ,  -0.   ,   0.   ,   0.   ,  -0.   ,\n",
       "         0.   ,  -0.   ,   0.   ,   0.   ,   0.   ,  -0.   ,   0.   ,\n",
       "         0.   ,   0.   ,  -0.   ,   0.   ,   0.   ,   0.   ,   0.   ,\n",
       "         0.   ,  -0.   ,   0.   ,   0.   ,  -0.   ,  -0.   ,   0.   ,\n",
       "        -0.   ,  -0.   ,  -0.   ,   0.   ,  -0.   ,  -0.   ,   0.   ,\n",
       "        -0.   ,   0.   ,  -0.   ,   0.   ,   0.   ,   0.   ,  -0.   ,\n",
       "        -0.   ,  -0.   ,   0.   ,   0.   ,  -0.   ,   0.   ,  -0.   ,\n",
       "         0.   ,  -0.   ,  -0.   ,   0.   ,  -0.   ,   0.   ,   0.   ,\n",
       "        -0.   ,  -0.   ,  -0.   ,   0.   ,   0.   ,   0.   ,  -0.   ,\n",
       "         0.   ,  -0.   ,  -0.   ,  -0.   ,   0.   ,  -0.   ,  -0.   ,\n",
       "         0.   ,  -0.   ,  -0.   ,   0.   ,  -0.   ,  -0.   ,  -0.   ,\n",
       "        -0.   ,   0.   ,   0.   ,  -0.   ,   0.   ,  -0.   ,   0.   ,\n",
       "        -0.   ,   0.   ,  -0.   ,   0.   ,   0.   ,   0.   ,   0.   ,\n",
       "        -0.   ,  -0.   ,   0.   ,  -0.   ,  -0.   ,   0.   ,  -0.   ,\n",
       "        -0.   ,   0.   ,  -0.   ,   0.   ,   0.   ,   0.   ,  -0.   ,\n",
       "        -0.   ,   0.   ,   0.   ,   0.   ,  -0.   ,   0.   ,  -0.   ,\n",
       "        -0.   ,  -0.   ,   0.   ,   0.   ,  -0.   ,   0.   ,  -0.   ,\n",
       "         0.   ,   0.   ,   0.   ,   0.   ,   0.   ,  -0.   ,   0.   ,\n",
       "         0.   ,  -0.   ,   0.   ,  -0.   ,  -0.   ,   0.   ,   0.   ,\n",
       "        -0.   ,   0.   ,   0.   ,   0.   ,   0.   ,  -0.   ,   0.   ,\n",
       "         0.   ,   0.   ,   0.   ,   0.   ,  -0.   ,  -0.   ,  -0.   ,\n",
       "        -0.   ,   0.   ,   0.   ,   0.   ,   0.   ,   0.   ,  -0.   ,\n",
       "         0.   ,   0.   ,  -0.   ,   0.   ,  -0.   ,   0.   ,  -0.   ,\n",
       "         0.   ,   0.   ,   0.   ,   0.   ,  -0.   ,  31.651,  -0.   ,\n",
       "         0.   ,  -0.   ,   0.   ,   0.   ,  -0.   ,   0.   ,  -0.   ])"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# After run model_experiment with complexity == 'polynomial'\n",
    "\n",
    "lr_ols = trained_models['ols']\n",
    "lr_lasso = trained_models['lasso']\n",
    "lr_ridge =trained_models['ridge']\n",
    "\n",
    "# check the coefficients from Lasso\n",
    "lr_lasso.coef_\n",
    "\n",
    "# compare them with OLS/Ridge models.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0.   , -28.739,  51.753,  52.133,   8.164,  -6.361,  -1.424,\n",
       "        -1.363,  -0.337,  -0.208,  16.527,   0.674, -13.022, -11.117,\n",
       "       -12.102,  -2.273,  -0.704,   9.254,   1.588,   1.59 ,   3.44 ,\n",
       "         3.984,  -5.031,   7.346,   6.8  ,   0.902,  -4.395,   1.347,\n",
       "        -9.183, -10.292,  -0.422,  -8.509,   9.012,   6.256,   0.871,\n",
       "        -3.995,   1.767,  -9.807,  -8.971,  -0.617,  -8.179,   9.757,\n",
       "         1.581,  -2.146,   0.595, -10.934,   2.73 ,  -4.953,  -5.902,\n",
       "         6.777,  -3.856,  -0.302,   5.336,   3.162,  -4.136,  -4.814,\n",
       "         0.042,   0.878,  -3.807,  -0.634,   0.089,   4.065,  -1.077,\n",
       "        -1.363,   1.465,  -1.156,  -0.036,  -4.077,  -0.337,   2.516,\n",
       "         2.642,   3.66 ,  -0.208,  -0.542,   0.656,  16.527,  -2.949,\n",
       "        -0.674, -12.591,  -2.494,  -2.944,   1.808,  -6.109,   3.953,\n",
       "         4.886,   6.839,  -3.68 ,   5.851,  -0.557,   1.762,   1.461,\n",
       "        -4.082,  -1.949,   2.525,   5.208,   2.951,  -0.011,   3.307,\n",
       "         2.241,   1.132,  -3.932,  -1.774,   3.086,   5.406,   3.299,\n",
       "         0.131,   3.508,   1.241,  -8.177,   5.222,  -1.633,   3.028,\n",
       "        -1.762,  -3.386,  -3.683,   6.026, -18.752,   2.535,   1.981,\n",
       "        -0.29 ,   4.93 ,   4.298,   3.91 , -18.1  ,  -1.593,  -9.023,\n",
       "        -1.377,  -1.001,   1.899, -18.35 ,  10.021,  -1.185,  -2.585,\n",
       "         1.784, -15.649,  -3.354,   1.092,   2.279, -28.74 ,  -0.081,\n",
       "        -1.381,  -5.353,   6.761, -27.602,   8.211,   8.058,  -4.645,\n",
       "         2.153,  -2.59 ,   4.822,  -0.066,   2.236,  -6.266,   5.108,\n",
       "         7.955,  -3.494,   2.217,  -2.471,   4.73 ,   0.167,   2.814,\n",
       "        -6.061,   4.396,  19.083,   3.382,   2.191,  -3.339,   1.901,\n",
       "         9.856,  -6.187,  -5.538,  22.695,  -6.575,  -7.275,   1.457,\n",
       "        -0.904,  -2.357,   1.285,  20.094,   2.937,   1.676,  -0.814,\n",
       "        -1.143,   0.311,  27.454,  -7.687,  -5.303,   0.329,  -2.243,\n",
       "        24.223,  -1.736,   1.567,  -8.633,  51.802,  -3.416,  -1.381,\n",
       "        12.565,  -1.88 ,  48.146,   7.904,  -2.35 ,   2.349,  -2.362,\n",
       "         4.664,   0.383,   3.203,  -5.694,   3.656,  19.436,   3.905,\n",
       "         1.915,  -2.19 ,   1.361,   7.493,  -4.71 ,  -5.636,  22.976,\n",
       "        -5.285,  -5.978,   1.175,  -2.217,  -3.34 ,   1.018,  19.685,\n",
       "         2.423,   2.349,  -1.158,  -2.347,   0.898,  27.433,  -8.491,\n",
       "        -3.919,  -0.157,  -2.142,  25.468,  -3.013,   1.33 ,  -8.181,\n",
       "        52.178,  -4.653,  -0.768,  12.785,  -1.637,  47.87 ,   4.237,\n",
       "         0.721,  -3.534,  -2.715,  -4.295,  -2.39 ,   9.663,   4.216,\n",
       "         8.195,   4.825,   2.645,   0.559,  10.462,  -0.346,   0.184,\n",
       "        -5.022,  -5.316,   9.194,   6.082,  -7.37 ,  -4.459,  -2.443,\n",
       "         2.832,   5.58 ,   6.482,   2.967,   8.468,  -7.495,   1.055,\n",
       "        -5.177,   8.085,  -0.206,  -3.22 ,  -2.669,   4.5  ,   4.796,\n",
       "        -3.425,   0.76 ,   1.403,  -2.805,  -3.064,  10.041,  -6.844,\n",
       "         3.815,   1.291,   0.626,   2.874,   8.511,   6.939,  -0.399,\n",
       "        -3.68 ,   4.052,  -1.835,   3.124,  -1.73 ,   7.9  ,  -3.116,\n",
       "         0.918,  -6.419,  -1.384,   9.058,  -7.147,   4.402,  -5.842,\n",
       "         0.982,  -0.046,   5.263,   0.719,   9.744,  -2.734,  -3.723,\n",
       "         4.186,  -4.741,   1.899,  -0.289,  -1.51 ,   1.641,  -0.967,\n",
       "        -2.41 ,  -1.423,  -1.92 ,   7.27 ,   3.295,  -4.372,  -0.842,\n",
       "        -1.363,   0.902,  -0.99 ,  12.009,  -2.544,  -0.265,  -0.99 ,\n",
       "        -9.467,  -0.169,  -1.379,   4.158,   3.025,  -0.524, -10.627,\n",
       "         0.445,  -0.337,   1.775,  11.512,   3.204,  -0.306,  -2.447,\n",
       "         3.24 ,   2.335,   3.046,  -1.809,  -0.208,  16.552,   0.683,\n",
       "        -0.577,  -2.363,  -0.464,  16.527,  -2.516,  14.561,   0.674])"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the coefficients from Lasso\n",
    "lr_ridge.coef_\n",
    "\n",
    "# compare them with OLS/Ridge models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Effect of Scaling Data__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([37., 19., 18.,  8.,  9.,  2.,  2.,  2.,  1.,  2.]),\n",
       " array([-1.055, -0.585, -0.114,  0.357,  0.827,  1.298,  1.769,  2.24 ,\n",
       "         2.71 ,  3.181,  3.652]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = np.random.exponential(scale = 3, size = 100)\n",
    "\n",
    "plt.hist(x)\n",
    "\n",
    "\n",
    "x_scaled = (x - x.mean())/x.std(ddof = 1)\n",
    "\n",
    "\n",
    "plt.hist(x_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Normalization__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([37., 19., 18.,  8.,  9.,  2.,  2.,  2.,  1.,  2.]),\n",
       " array([-0.073, -0.04 , -0.008,  0.025,  0.057,  0.089,  0.122,  0.154,\n",
       "         0.186,  0.219,  0.251]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.subplot(1)\n",
    "x_normalized = (x - x.mean())/np.sqrt(x.dot(x))\n",
    "plt.hist(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "#### Effect of $\\alpha$ in Lasso and Ridge\n",
    "\n",
    "<img src=\"lasso_effect_of_lambda.png\" alt=\"Lasso-Lambda\" style=\"width: 500px;\"/>\n",
    "\n",
    "<img src=\"ridge_effect_of_lambda.png\" alt=\"Lasso-Lambda\" style=\"width: 500px;\"/>\n",
    "\n",
    "<a name='questions'></a>\n",
    "\n",
    "\n",
    "#### Appendix\n",
    "<a name='appendix'></a>\n",
    "\n",
    "Here I would like to add some reading material that I found useful while working with the code.\n",
    "\n",
    "\n",
    "- [pd.get_dummies or OneHotEncoder? - Read second answer](https://stackoverflow.com/questions/36631163/pandas-get-dummies-vs-sklearns-onehotencoder-what-are-the-pros-and-cons)\n",
    "\n",
    "- [On dummy variable trap](https://www.algosome.com/articles/dummy-variable-trap-regression.html)\n",
    "\n",
    "- [sklearn.preprocessing.PolynomialFeatures documentation](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.PolynomialFeatures.html)\n",
    "\n",
    "- [A great notebook on Lasso and Ridge](https://github.com/gokererdogan/JaverianaMLCourse/blob/master/Lectures/05.pdf)\n",
    "\n",
    "- [Another good blog post on Lasso and Ridge](https://www.analyticsvidhya.com/blog/2016/01/complete-tutorial-ridge-lasso-regression-python/)\n",
    "\n",
    "- Learn.co -- Section-28 Lasso-Ridge\n",
    "\n",
    "- [Toward Datascience Article](https://towardsdatascience.com/understanding-the-bias-variance-tradeoff-165e6942b229)\n",
    "\n",
    "- [ISLR](http://faculty.marshall.usc.edu/gareth-james/ISL/) 2.2.2 The Bias-Variance Trade-off and 6.2 Shrinkage Methods\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Image Sources in order of appearance: \n",
    "- https://docs.aws.amazon.com/machine-learning/latest/dg/model-fit-underfitting-vs-overfitting.html\n",
    "\n",
    "- https://towardsdatascience.com/ensemble-methods-bagging-boosting-and-stacking-c9214a10a205\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Initialization Cell",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 122,
   "position": {
    "height": "40px",
    "left": "1778px",
    "right": "20px",
    "top": "120px",
    "width": "250px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "none",
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
